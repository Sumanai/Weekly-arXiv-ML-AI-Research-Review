# Введение

Платформа искусственного интеллекта – это интегрированная технологическая и организационная среда для создания, развёртывания и управления AI-решениями. Ей присущи следующие характеристи:

## Многоуровневый интерфейс API
- От низкоуровневого доступа к «сырым» моделям  
- До среднеуровневых средств управления контекстом/диалогами  
- И высокоуровневых готовых бизнес-сценариев

## Инструментарий разработчика
- Встроенные средства расширения возможностей модели:
  - Вызов функций (внешних API)
  - Агенты на базе ИИ
  - Поиск (web и deep search)
  - Интерпретатор кода
  - Системы RAG
  - Интеграция с внешними сервисами и др.

## Гибкие варианты развёртывания
- Облачные (SaaS)
- Локальные (on-premise)
- Гибридные
- Изолированные (air-gapped) установки

## Экосистемная интеграция
- Связь с другими смежными сервисами:
  - Генерация контента (текст-в-изображение (T2I), текст-в-видео (T2V), текст-в-аудио (T2S), аудио-в-текс (S2T) и пр.)
  - Обработка данных
  - Обучение моделей
  - Отраслевые специализированные приложения

В данном обзоре сравниваются несколько ведущих AI-платформ по указанным техническим аспектам. Рассматриваются возможности и особенности:

- **Yandex DataSphere**  
- **OpenAI API**  
- **Anthropic Claude API**  
- **Google AI Studio (Vertex AI)**  
- **Mistral AI (платформа “Le Chat”)**  
- **Alibaba Cloud Qwen API**  
- **AWS**

Анализ ориентирован на инженерные команды, поэтому акцент сделан на:

- Функциональности API  
- Опциях для разработчиков  
- Вариантах развёртывания  
- Интеграциях  

Ниже приведён поочерёдный обзор каждой платформы с технической точки зрения, а затем — их сравнительная оценка по ключевым параметрам.

# Yandex DataSphere (YandexGPT)

## Общая характеристика

Yandex DataSphere – облачный сервис для разработки машинного обучения с удобным интерфейсом, объединяющий все необходимые инструменты и масштабируемые ресурсы для полного цикла ML-разработки.  

DataSphere предоставляет привычную Jupyter-ноутбук среду и автоматическое управление инфраструктурой, позволяя быстро запускать вычислительные ресурсы для обучения моделей без ручного администрирования.

Платформа интегрирована с Yandex Cloud и предназначена как для экспериментов, так и для деплоя моделей в продакшен.

---

## API и уровни доступа

В экосистеме Yandex Cloud доступны собственные большие языковые модели под брендом YandexGPT (актуально семейство YandexGPT 4/5). API поддерживает два режима работы:  
- **режим prompt** (одношаговая генерация текста)  
- **режим chat** (многоходовой диалог)  

Последний позволяет сохранять контекст беседы через роли `user`, `assistant`, `system` — аналогично OpenAI.

На высоком уровне Yandex предлагает интеграцию LLM в прикладные сценарии — например, ассистент «Алиса» и создание чат-ботов для бизнеса. В документации Yandex присутствует **AI Assistant API**, упрощающий разработку полноценных диалоговых агентов.

Кроме того, DataSphere поддерживает **дообучение (fine-tuning)** моделей: есть инструменты для дообучения собственной версии YandexGPT на пользовательских данных прямо в облаке.

---

## Инструменты разработчика

Функциональность YandexGPT во многом совместима с OpenAI. В частности, **вызов функций (function calling)** реализован: разработчик может описать внешнюю функцию (схема JSON), и модель YandexGPT Pro (или другие модели, которые уже хостятся Yandex Cloud) сама решит, когда её вызвать, и вернёт JSON с аргументами.

Благодаря этому модель способна обращаться к внешним API, базам данных и т.п. — по аналогии с GPT-4.

Yandex также предоставляет инструменты для построения **RAG-сценариев** (Retrieval-Augmented Generation). Например, доступны готовые решения по соединению LLM с поиском по документам — в материалах Yandex упоминается коннектор к библиотеке документов и примеры создания Telegram-бота с RAG + функции.

В DataSphere интегрированы и классические сервисы Yandex Cloud: можно вызывать модели распознавания речи, синтеза речи (SpeechKit) и др., расширяя возможности AI-приложений.

Также DataSphere поддерживает запуск кода: например, в Jupyter-ноутбуках можно выполнять Python-скрипты для подготовки данных, постобработки ответов модели и т.д.  
*(Примечание: в самом YandexGPT встроенного интерпретатора кода нет, но это можно реализовать через function calling.)*

---

## Развёртывание

По умолчанию DataSphere — облачная SaaS-платформа на Yandex Cloud. Однако Yandex предлагает гибридные возможности:  
- **DataSphere Jobs** позволяют подключать облачные GPU-ресурсы к локальной среде разработки через CLI, реализуя гибридный сценарий (локальный код + удалённое ускорение).

Для изолированных случаев Yandex предоставляет **Dedicated-режим** — выделенное окружение в облаке, аналог локального сервера, но полностью под контролем клиента (без шаринга ресурсов).

Что касается **on-premise**: Yandex открыто заявляет о стратегии развития открытых моделей — так, семейство YandexGPT 5 доступно не только в облаке и ассистенте «Алиса», но и частично в опенсорс-варианте.

Ранее Yandex публиковал модели **YaLM 100B**, **YaLM 2.0** в открытый доступ, поэтому можно ожидать возможность установить аналог YandexGPT в закрытом контуре.

Таким образом, для клиентов доступен гибкий выбор: использовать полностью управляемый облачный сервис **либо** брать открытые модели Yandex и разворачивать их самостоятельно.

---

## Интеграция и экосистема

Платформа Yandex ориентирована на русский язык и интегрирована с сервисами компании. Например:  
- генеративные модели текста могут работать совместно с сервисом **Yandex Translate**  
- для мультимодальных функций доступны **Yandex Vision** и **SpeechKit** (распознавание изображений, речи)

Для генерации контента Yandex предлагает отдельный сервис **YandexART** — нейросеть для генерации изображений по текстовому описанию (text-to-image). Он доступен бизнес-пользователям и интегрируется с DataSphere.

Также Yandex Cloud имеет **DataSphere Marketplace**, где могут публиковаться готовые решения и модели от сторонних разработчиков.

В экосистеме есть:  
- обучающие программы (Yandex обучает специалистов через **ШАД**, **Катапульт** и др.)  
- активное комьюнити (например, открытый чат DataSphere, мероприятия и гранты на использование облака).

---

## Итог

**Yandex DataSphere** представляет собой полноценную среду ML/AI с особым упором на локальный рынок и возможности кастомизации под нужды компаний, которые ценят как облачное удобство, так и контроль над моделями.

# Характеристики Yandex DataSphere (YandexGPT)

| Функция | Поддержка в Yandex DataSphere | Описание |
|--------|-------------------------------|--------|
| **REST API** | ✅ Есть | Предоставляется API для взаимодействия с YandexGPT, включая режимы prompt и chat. Поддержка JSON-интерфейса для интеграции в приложения. |
| **Streaming** | ✅ Есть | Поддержка асинхронного и синхронного режимов генерации ответов (включая потоковую передачу — streaming). |
| **Batch API** | ⚠️ Асинхронный режим | Платформа поддерживает асинхронную обработку запросов, но отдельный batch-режим с оптимизацией и скидками не анонсирован. |
| **Function Calling** | ✅ Реализовано | Поддерживается вызов внешних функций: модель (YandexGPT Pro, Llama 70B etc...) может определять необходимость вызова и возвращать аргументы в формате JSON. |
| **Fine-tuning** | ✅ В preview | Доступна возможность дообучения моделей (fine-tuning) на пользовательских данных прямо в облаке. Находится в стадии preview. |
| **OpenAI-совместимость** | ✅ Частичная | Функциональность YandexGPT во многом аналогична OpenAI (роли в чате, function calling, структура запросов), но полная совместимость требует адаптации. |
| **Режимы работы API** | ✅ Prompt и Chat | Поддержка одношаговой генерации (prompt) и многоходового диалога с контекстом (chat) с ролями `user`, `assistant`, `system`. |
| **AI Assistant API** | ✅ Есть | Специализированный API для упрощённой разработки диалоговых агентов и чат-ботов. |
| **RAG-сценарии** | ✅ Поддерживается | Инструменты для построения RAG: интеграция с поиском по документам, коннекторы к базам знаний, примеры реализации (например, Telegram-боты). |
| **Интеграция с Yandex сервисами** | ✅ Полная | Встроенная поддержка SpeechKit (распознавание и синтез речи), Yandex Vision, Yandex Translate, YandexART (генерация изображений). |
| **Jupyter-ноутбуки** | ✅ Есть | Привычная среда разработки на базе Jupyter, встроенная в DataSphere. |
| **Запуск кода** | ✅ Есть | Поддержка выполнения Python-скриптов в ноутбуках для подготовки данных, постобработки и интеграции с внешними системами. |
| **Гибридное развёртывание** | ✅ Есть | DataSphere Jobs позволяют использовать облачные GPU-ресурсы из локальной среды через CLI (локальный код + удалённые вычисления). |
| **Dedicated-режим** | ✅ Есть | Выделенное окружение в облаке без шаринга ресурсов, полностью под контролем клиента. |
| **On-premise / Self-hosted** | ⚠️ Частично (через open-source) | Открытые модели (YaLM 100B, YaLM 2.0, частично YandexGPT 5) позволяют развертывать аналоги LLM в закрытом контуре. Полный on-premise — через самостоятельное развёртывание. |
| **Мультимодальность** | ✅ Через интеграцию | Поддержка мультимодальных сценариев через Yandex Vision (изображения) и SpeechKit (речь), но нативная мультимодальная модель не указана. |
| **DataSphere Marketplace** | ✅ Есть | Платформа для публикации и использования готовых решений, моделей и шаблонов от сторонних разработчиков. |
| **Поддержка русского языка** | ✅ Оптимизирована | Все сервисы и модели оптимизированы для русского языка, что делает платформу особенно удобной для локального рынка. |
| **Безопасность и соответствие** | ✅ ISO, GDPR, 152-ФЗ и др. | Соответствие международным и российским стандартам: ISO, PCI DSS, GDPR, 152-ФЗ РФ. Собственный стандарт защиты инфраструктуры. |
| **Поддержка** | ✅ Круглосуточная (в расширенных тарифах) | Поддержка на русском и английском языках, включая 24/7 в бизнес-тарифах. |
| **Гранты для стартов** | ✅ До 10 000 ₽ для юрлиц | Новые пользователи могут получить стартовый грант для тестирования платформы. |
| **Обучение и комьюнити** | ✅ Есть | Образовательные программы (ШАД, Катапульт), открытые чаты, мероприятия, гранты на использование облака. |

# OpenAI API (ChatGPT)

## Общая характеристика

OpenAI API — одно из самых популярных решений для доступа к мощным языковым моделям, включая GPT-3.5 и GPT-4. Это облачный API-сервис, предоставляющий широкие возможности: генерацию текста, ведение чат-диалогов, создание эмбеддингов, а также специализированные модели для генерации изображений (DALL·E) и распознавания речи (Whisper). 

**OpenAI API устанавливает новые стандарты в области AI-возможностей** благодаря революционным моделям 2025 года и комплексной экосистеме инструментов разработки. API отличается высоким качеством моделей, стабильностью и широкой поддержкой со стороны разработчиков. Экосистема OpenAI характеризуется обилием сторонних библиотек, фреймворков и активным сообществом, что делает интеграцию и разработку на базе API особенно удобной.

---

## Breakthrough модели и производительность 2025

### Флагманские модели нового поколения

**GPT-5 (август 2025)** представляет качественный прорыв в области reasoning и мультимодальности:
- **94.6% точность на AIME math** — революционные возможности математических рассуждений
- **74.9% на SWE-bench coding** при **80% снижении галлюцинаций** 
- **Контекст 400K токенов** (272K input + 128K output)
- **Агрессивное ценообразование**: $1.25/$10 за миллион токенов

**GPT-4.1 series** расширяет возможности контекста:
- **1M контекст** для работы с объемными документами
- **+21.4% улучшение** в coding задачах по сравнению с предыдущими версиями

### Мультимодальные возможности

**gpt-realtime API** достиг general availability с существенными улучшениями:
- Устранение лимитов сессий
- **20% снижение стоимости** до $32/$64 за миллион аудио-токенов
- Exclusive голоса **Cedar и Marin**
- Поддержка изображений в реальном времени
- **SIP calling** для телефонной интеграции

**DALL-E интеграция** предоставляет комплексные возможности генерации изображений:
- **GPT Image 1** и **DALL-E 3** для T2I генерации
- Стоимость от **$0.01 до $0.17 за изображение**

---

## API интерфейсы и уровни

OpenAI API предоставляет **трехуровневую архитектуру** для различных сценариев интеграции:

- **Высокоуровневый Responses API**: упрощенный интерфейс для быстрой интеграции
- **Базовый уровень**: прямые вызовы моделей через endpoints:
  - `completions` — для одиночной генерации текста
  - `chat/completions` — для диалогового формата с поддержкой ролей `user`, `assistant`, `system`
- **Прямые HTTP endpoints**: максимальная гибкость для кастомных реализаций

- **Средний уровень**: использование контекста диалога. Разработчик управляет историей общения, передавая её в каждом запросе. Модель демонстрирует сильные способности к следованию инструкциям, особенно через системные сообщения, которые задают поведение агента.

- **Высокоуровневые сценарии**: сам API не предоставляет готовых бизнес-решений, но в экосистеме существуют расширенные продукты, такие как **ChatGPT Enterprise** и **Azure OpenAI Service**. Они предлагают дополнительные функции: увеличенный контекст, интеграция с корпоративными данными, плагины и расширенные возможности безопасности.

---

## Комплексный инструментарий разработчика

### Advanced Function Calling

Эволюция **function calling**, представленная в 2023 году, получила существенные улучшения:

**Structured Outputs** с **гарантированным JSON Schema соответствием** при `strict: true`:
- Строгое соответствие схеме без отклонений
- **Параллельные вызовы функций** для оптимизации производительности
- Поддержка сложных вложенных структур данных

**Agents SDK** с встроенной наблюдаемостью:
- Создание сложных AI-агентов с автоматическим логированием
- Отслеживание цепочек выполнения и отладка
- Enterprise-готовые инструменты мониторинга

**Model Context Protocol (MCP)** стандартизирует подключение к внешним источникам данных:
- Унифицированный интерфейс для различных систем
- Безопасное подключение к корпоративным базам данных
- Автоматическое управление контекстом и релевантностью

### Встроенные инструменты и возможности

**Code Interpreter** ($0.03/сессия):
- Выполнение Python-кода в изолированной среде
- Анализ данных, визуализация, математические вычисления
- Интеграция с файловой системой

**File Search**:
- Семантический поиск по документам
- Поддержка множества форматов файлов
- RAG-интеграция для работы с базами знаний

**Web Search** (бесплатно для GPT-4o/GPT-4.1):
- Доступ к актуальной информации в реальном времени
- Интеграция результатов поиска в генерацию ответов

**Computer Use** (экспериментальный):
- Управление графическими интерфейсами
- Автоматизация задач на уровне операционной системы
- Взаимодействие с веб-приложениями и десктоп-программами

### Fine-tuning и настройка

OpenAI поддерживает дообучение моделей с расширенными возможностями:
- **GPT-3.5-Turbo** — полная поддержка fine-tuning для адаптации под специфические задачи
- **GPT-4.1** — ограниченные возможности fine-tuning для enterprise-клиентов
- **GPT-5** — на стадии beta-тестирования возможностей дообучения

### Дополнительные инструменты
- **Системные сообщения**: расширенные возможности управления поведением модели
- **Модерация контента**: улучшенная проверка через endpoint `/moderation` с поддержкой мультимодального контента
- **Агентные фреймворки**: экосистема активно использует LangChain, LlamaIndex и другие инструменты для построения цепочек рассуждений, RAG и агентов на основе GPT

---

## Развёртывание

OpenAI API доступен **исключительно как облачный сервис**:
- Через инфраструктуру OpenAI в различных географических регионах
- Через **Azure OpenAI Service** — партнёрское решение с Microsoft, позволяющее использовать те же модели в рамках Azure, что важно для корпоративных клиентов, требующих соответствия стандартам и интеграции с существующей ИТ-средой

### On-premise и гибридность
- **On-premise развёртывание** моделей GPT-5, GPT-4 или GPT-3.5 **невозможно**: исходный код не открыт, лицензия запрещает локальный запуск
- **Гибридные сценарии**: возможны только через вызов облачного API из локальных приложений
- **Air-gapped среды** (полностью изолированные от интернета): не поддерживаются. Для таких случаев необходимо использовать open-source модели (например, Llama, Mistral) в связке с собственной инфраструктурой

---

## Экосистема и интеграции

OpenAI обладает одной из самых развитых экосистем среди LLM-провайдеров:

- **Интеграции**: тысячи готовых коннекторов с CRM, IDE, офисными пакетами (например, плагины для Excel, Word, Google Workspace)
- **Маркетплейс плагинов**: развивающаяся платформа, позволяющая подключать сторонние сервисы (Zapier, Expedia и др.) к ChatGPT
- **ChatGPT Enterprise**: включает функцию **Retrieval**, позволяющую подключать внутренние базы знаний и документы компании
- **Документация и обучение**: OpenAI предоставляет подробную документацию, примеры (Cookbook), инструменты оценки (Evals) и проводит соревнования для разработчиков
- **Сообщество**: активное, с постоянным обменом best practices, шаблонами и инструментами

---

## Итог

OpenAI API предлагает **лидирующие в отрасли языковые модели** с революционными возможностями reasoning и мультимодальности. **GPT-5 и GPT-4.1 series** устанавливают новые стандарты производительности, а **комплексный инструментарий разработчика** включает:
- **Structured Outputs** с гарантированным соответствием схемам
- **Agents SDK** для enterprise-разработки  
- **Model Context Protocol** для стандартизированной интеграции
- **Встроенные инструменты**: Code Interpreter, File Search, Web Search, Computer Use
- **Мультимодальные возможности**: голосовые интерфейсы, генерация изображений, real-time обработка

Однако использование ограничено **облачным доступом**, а **on-premise развёртывание невозможно**. Это делает OpenAI идеальным выбором для команд, которым важны:
- Передовое качество генерации и reasoning
- Комплексные мультимодальные возможности  
- Широкая поддержка сообществом и богатая экосистема
- Быстрое внедрение и enterprise-готовые инструменты
- Агрессивное ценообразование при высокой производительности

Для организаций, требующих полного контроля, изоляции данных или локального запуска моделей, OpenAI может быть недостаточным — в таких случаях предпочтительны open-source или гибридные решения.

# Характеристики OpenAI API (2025)

| Функция | Поддержка в OpenAI | Описание |
|--------|-------------------|--------|
| **REST API** | ✅ Есть | Прямые HTTP-вызовы через `completions` и `chat/completions`. Поддержка высокоуровневого Responses API и низкоуровневых endpoints. |
| **Streaming** | ✅ Есть | Полная поддержка потоковой передачи (streaming) ответов в реальном времени для всех моделей. |
| **Batch API** | ✅ 50% скидка | Поддержка пакетной обработки запросов с существенной скидкой на стоимость токенов. |
| **Function Calling** | ✅ Tools (расширенные) | Поддержка вызова функций с JSON-схемами. Включает **Structured Outputs** с `strict: true`, параллельные вызовы и соответствие схеме. |
| **Agents SDK** | ✅ Есть | Встроенный SDK для создания AI-агентов с возможностями логирования, отладки и enterprise-мониторинга. |
| **Model Context Protocol (MCP)** | ✅ Есть | Стандартизированный протокол для подключения к внешним источникам данных (базы, API, файлы). |
| **Fine-tuning** | ✅ Есть (ограниченно) | Поддержка дообучения: GPT-3.5-Turbo — полная, GPT-4.1 — для enterprise, GPT-5 — в бета-тестировании. |
| **OpenAI-совместимость** | ✅ Нативная | Все модели и инструменты изначально совместимы с экосистемой OpenAI. |
| **Контекстное окно** | ✅ До 1M токенов | GPT-4.1 поддерживает контекст до 1 миллиона токенов. GPT-5 — 400K (272K input + 128K output). |
| **GPT-5 (2025)** | ✅ Доступна | Флагманская модель с прорывом в reasoning: 94.6% на AIME math, 74.9% на SWE-bench, на 80% меньше галлюцинаций. |
| **GPT-4.1 series** | ✅ Есть | Улучшенная версия GPT-4 с контекстом 1M токенов и +21.4% в задачах программирования. |
| **Мультимодальность** | ✅ Полная | Поддержка текста, изображений, аудио и видео. Интеграция с DALL·E, Whisper и real-time визуальным анализом. |
| **gpt-realtime API** | ✅ General Availability | Реальное время обработки аудио и видео. Поддержка голосов Cedar и Marin, SIP calling, сессии без ограничений. |
| **DALL·E и генерация изображений** | ✅ Есть | Интеграция с DALL·E 3 и GPT Image 1. Стоимость от $0.01 до $0.17 за изображение. |
| **Code Interpreter** | ✅ Есть ($0.03/сессия) | Выполнение Python-кода в изолированной среде: анализ данных, визуализация, вычисления. |
| **File Search** | ✅ Есть | Семантический поиск по загруженным документам. Поддержка RAG-сценариев и интеграция с базами знаний. |
| **Web Search** | ✅ Бесплатно (для GPT-4o/4.1) | Доступ к актуальным данным из интернета. Результаты автоматически интегрируются в ответы. |
| **Computer Use** | ✅ Экспериментально | Возможность управления GUI: автоматизация веб-интерфейсов, десктоп-приложений и операционной системы. |
| **Системные сообщения** | ✅ Есть | Гибкое управление поведением модели через системные промпты без дообучения. |
| **Модерация контента** | ✅ Есть | Встроенный endpoint `/moderation` для проверки текста и мультимодального контента на безопасность. |
| **Развёртывание** | ❌ Только облако | Доступен исключительно как облачный сервис (OpenAI или Azure OpenAI). On-premise невозможен. |
| **Гибридные сценарии** | ⚠️ Через API | Возможна интеграция с локальными приложениями, но все вычисления происходят в облаке. |
| **Air-gapped среды** | ❌ Нет | Полностью изолированные (без интернета) сценарии невозможны. |
| **Azure OpenAI Service** | ✅ Есть | Интеграция с Microsoft Azure для корпоративных клиентов: безопасность, compliance, управление доступом. |
| **ChatGPT Enterprise** | ✅ Есть | Расширенные возможности: Retrieval (подключение баз знаний), аналитика, безопасность, SSO. |
| **Плагины и маркетплейс** | ✅ Есть | Поддержка плагинов и интеграций с внешними сервисами (Zapier, Expedia и др.). |
| **Поддержка языков** | ✅ Многоязычная | Отличная поддержка английского, русского и других языков. Модели обучены на мультиязычных данных. |
| **Документация и обучение** | ✅ Полная | Подробная документация, Cookbook, Evals, примеры и руководства для разработчиков. |
| **Сообщество и экосистема** | ✅ Активная | Одна из самых развитых экосистем: LangChain, LlamaIndex, тысячи интеграций, фреймворков и плагинов. |
| **Ценообразование** | ✅ Агрессивное | GPT-5: $1.25/$10 за миллион токенов. gpt-realtime: $32/$64 за миллион аудио-токенов. |
| **Безопасность и соответствие** | ✅ ISO, GDPR, PCI DSS | Соответствие международным стандартам безопасности и конфиденциальности данных. |
| **Поддержка** | ✅ 24/7 (в enterprise) | Круглосуточная поддержка для корпоративных клиентов. Доступна на английском и других языках. |


# Anthropic Claude API

Claude сегодня — не просто набор моделей, а многоуровневая платформа API, которую можно использовать по-разному: от «сырых» вызовов генеративной модели до готовых сценариев с поиском по вебу, исполнением кода и управлением GUI. На нижнем уровне разработчику доступен Messages API со стримингом, на среднем — строгая оркестрация инструментов, структурированный вывод и управление контекстом, на верхнем — высокоуровневые сервисы вроде Web Search, Code Execution, Computer Use и Claude Code.

---

## Профиль и модельная линейка

Ключевые семейства моделей — **Claude 4** (Opus 4, Sonnet 4) и **Claude 3.7 Sonnet**. Поддерживаются мультимодальные входы (текст + изображения). В **Sonnet 4** заявлены **вывод до 64K токенов** и **контекст до 1M токенов**. Доступны кеширование промптов и batch-режим. Подключение возможно напрямую к Anthropic API, а также через **AWS Bedrock** и **Google Vertex AI** — с официальными инструкциями и SDK-обёртками.

---

## Многоуровневый интерфейс API

### Низкий уровень: «сырые» модели и масштабирование

Базовая точка входа — **Messages API** с **SSE-стримингом**: можно вести одиночные диалоги и работать со stateless-контекстом, получая ответы потоком и контролируя ошибки. Для массовых задач предусмотрен **Batch/Message Batches API** — асинхронная пакетная обработка десятков тысяч запросов, со встроенной SDK-поддержкой. Для задач с более глубокой проработкой ответов доступен режим **Extended Thinking** с потоковым выводом рассуждений.

### Средний уровень: управление контекстом и диалогами

В консоли можно настраивать **системные подсказки**, **рабочие пространства** и **ключи** для сегментации приложений и лимитов. Центральная способность уровня — **Tool Use (функции)**: описываем инструмент через `name/description/input_schema` (JSON Schema), а модель сама решает, когда его вызывать. Поддерживаются **параллельные вызовы** и «token-efficient tool use», включая **тонкую потоковую передачу аргументов** для снижения латентности. Для **структурированного вывода** применяется жёсткая схема через инструменты или контракты запроса.

### Высокий уровень: готовые сценарии и надстройки

**Web Search Tool** даёт серверный поиск по сети: модель сама решает, когда искать, и возвращает ответ с цитатами источников. **Code Execution** предоставляет песочницу Python для аналитики и прототипирования. **Computer Use (beta)** позволяет агентно управлять GUI (скриншоты, клавиатура, мышь) из API, функция доступна также в Bedrock и Vertex. Наконец, **Claude Code** — агентное программирование (CLI/IDE), дифф-правки и интеграция через MCP, доступно в бизнес-линейках и через Bedrock/Vertex.

---

## Инструментарий разработчика

Anthropic продвигает **декларативный подход** к инструментам: разработчик описывает схему (`input_schema`), а модель сама расходует токены и может вызывать несколько инструментов параллельно. Для «агентов» рекомендуются **простые композиции** с циклом планирования/исполнения вместо громоздких фреймворков, для действий в реальном окружении используются **Computer Use** и **Claude Code**. Поиск решается встроенным **Web Search Tool** (в т.ч. с ограничением доменов и обязательным цитированием), а для длительных исследовательских сессий предусмотрены **Research mode/Integrations**. **RAG-сценарии** нативно не реализованы из коробки, только поддержаны официальными методичками по **Contextual Retrieval** (контекстные эмбеддинги/BM25), готовыми гайдами и интеграциями через LangChain/LlamaIndex/векторные БД. SDK доступны для **Python** и **JavaScript**, включая адаптеры для Bedrock/Vertex.

---

## Варианты развёртывания

**SaaS (Anthropic Cloud)** — прямой API и консоль. Для строгих требований безопасности и резидентности (ЕС) применяют облачные провайдеры:

* Через **AWS Bedrock**: **частные VPC-эндпоинты** (AWS PrivateLink), унифицированный Converse API, изоляция трафика и даже доступ в закрытых средах вплоть до **AWS Top Secret Cloud**.
* Через **Google Vertex AI**: развёртывание в инфраструктуре GCP, **VPC Service Controls**, пакетные предсказания и управляемая интеграция с сервисами Google Cloud.

Полностью автономных **on-prem/air-gapped** сборок Anthropic не предоставляет. Для «максимально изолированных» сценариев на практике используют закрытые облачные зоны и периметры VPC-уровня.

---

## Экосистемная интеграция

Anthropic продвигает **MCP (Model Context Protocol)** — открытый протокол подключения внешних инструментов и данных. Он поддерживается в Claude Code, клиентах и сторонних серверах. Для задач без собственного кроулера доступны официальные **Integrations** и расширенный **Research-режим**, сочетающие веб-поиск и подключённые источники. Для генерации медиа у Anthropic **нет нативных T2I/T2V/TTS/S2T**.

---

## Вывод

**Anthropic Claude API** зрел как **платформа**: снизу — низкоуровневые **Messages/Batch**, посередине — строгое управление контекстом и **Tool Use**, сверху — надстройки **Web Search**, **Code Execution**, **Computer Use** и **Claude Code**. Для предприятий критично, что через **AWS Bedrock** и **Google Vertex AI** достигаются VPC/PrivateLink/VPC-SC, а для **API/Work** действует строгая политика данных. Единственное существенное ограничение — отсутствие true on-prem/air-gapped. В итоге Claude — сильная база для **RAG**, **агентных сценариев** и **код-ассистентов** с расширяемостью через **MCP** и богатые интеграции.

# Характеристики Anthropic Claude API

| Функция | Поддержка в Anthropic Claude | Описание |
|--------|-----------------------------|--------|
| **Messages API** | ✅ Есть | Основной низкоуровневый интерфейс для взаимодействия с моделью. Поддерживает диалоговый формат с ролями `user`, `assistant` и системными сообщениями. |
| **Streaming** | ✅ SSE-стриминг | Поддержка потоковой передачи ответов через Server-Sent Events (SSE), включая стриминг аргументов при вызове инструментов. |
| **Batch API** | ✅ Message Batches | Асинхронный Batch API для массовой обработки тысяч запросов. Поддерживается через SDK. |
| **Extended Thinking** | ✅ Есть | Режим глубоких рассуждений с потоковым выводом цепочки мышления модели. Улучшает качество сложных ответов. |
| **Tool Use (Function Calling)** | ✅ Есть | Поддержка декларативного вызова инструментов: модель сама решает, когда вызывать функцию, и возвращает аргументы по JSON-схеме. |
| **Параллельные вызовы инструментов** | ✅ Есть | Модель может одновременно вызывать несколько инструментов в одном шаге, оптимизируя токены и латентность. |
| **Token-efficient Tool Use** | ✅ Есть | Оптимизированная передача аргументов — токены расходуются только на фактически используемые инструменты. |
| **Структурированный вывод (Structured Outputs)** | ✅ Через инструменты | Жёсткое соответствие схеме достигается через `input_schema` в Tool Use. Нативного `response_format` как в OpenAI — нет. |
| **Web Search Tool** | ✅ Есть | Встроенный серверный веб-поиск: модель сама инициирует запрос, возвращает ответ с цитатами и источниками. Поддержка ограничения доменов. |
| **Code Execution** | ✅ Есть | Песочница для выполнения Python-кода: анализ данных, визуализация, вычисления. Доступна в API и через AWS Bedrock / Google Vertex AI. |
| **Computer Use (beta)** | ✅ Есть | Возможность агентного управления GUI: эмуляция мыши, клавиатуры, обработка скриншотов. Доступна в API, Bedrock и Vertex. |
| **Claude Code** | ✅ Есть | Агент для программирования: анализ кода, генерация правок (diff), интеграция с IDE/CLI через MCP. Доступен в бизнес-планах и через облачные провайдеры. |
| **Model Context Protocol (MCP)** | ✅ Есть | Открытый протокол для подключения внешних инструментов и источников данных. Поддерживается в Claude Code и сторонних интеграциях. |
| **RAG-сценарии** | ⚠️ Поддержаны методиками | Нативного RAG нет, но есть официальные гайды по Contextual Retrieval (эмбеддинги + BM25), интеграции с LangChain, LlamaIndex и векторными БД. |
| **Мультимодальность** | ✅ Текст + Изображения | Поддержка загрузки изображений в запросе. Модель анализирует визуальный контент и отвечает на его основе. |
| **Контекстное окно** | ✅ До 1M токенов | Модель **Claude 3.7 Sonnet** и **Sonnet 4** поддерживают контекст до 1 миллиона токенов. |
| **Вывод (output)** | ✅ До 64K токенов | Максимальная длина генерации — до 64 000 токенов. |
| **Кеширование промптов** | ✅ Есть | Поддержка кеширования системных промптов и частей контекста для снижения стоимости и ускорения ответов. |
| **Fine-tuning** | ❌ Нет | Anthropic не предоставляет возможности дообучения моделей на пользовательских данных. |
| **OpenAI-совместимость** | ⚠️ Через адаптеры | Прямая совместимость отсутствует, но возможна реализация через прокси-сервисы или обёртки (например, в LangChain). |
| **Развёртывание** | ✅ SaaS (Anthropic Cloud) | Основной способ — через прямой API и консоль Anthropic. |
| **AWS Bedrock** | ✅ Есть | Полная интеграция с AWS Bedrock, включая PrivateLink, VPC-эндпоинты, Converse API и доступ в изолированных средах (вплоть до Top Secret Cloud). |
| **Google Vertex AI** | ✅ Есть | Поддержка через Google Vertex AI с VPC Service Controls, пакетными предсказаниями и интеграцией с GCP. |
| **On-premise / Air-gapped** | ❌ Нет | Полностью изолированные (локальные или без интернета) развёртывания невозможны. |
| **Гибридные сценарии** | ⚠️ Через VPC и PrivateLink | Возможны через AWS Bedrock и Google Vertex AI с изоляцией трафика на уровне VPC. |
| **Системные подсказки** | ✅ Есть | Поддержка системных сообщений для управления поведением модели (например, стиль, формат, задача). |
| **Рабочие пространства и ключи** | ✅ Есть | В консоли доступно управление workspace, API-ключами, лимитами и сегментацией проектов. |
| **Research Mode / Integrations** | ✅ Есть | Режим для исследовательских задач: комбинирует веб-поиск, подключённые источники и интеграции с внешними базами. |
| **Поддержка языков** | ✅ Многоязычная | Отличная поддержка английского, русского и других языков. Модели обучаются на мультиязычных данных. |
| **SDK** | ✅ Python, JavaScript | Официальные SDK для Python и JavaScript, включая поддержку Bedrock и Vertex. |
| **MCP-интеграции** | ✅ Есть | Поддержка Model Context Protocol в Claude Code и сторонних серверах для стандартизированного подключения инструментов. |
| **Документация и обучение** | ✅ Полная | Подробная документация, примеры, гайды по RAG, интеграциям и best practices. |
| **Поддержка** | ✅ Есть | Техническая поддержка для бизнес-клиентов. Доступна на английском языке. |
| **Соответствие стандартам** | ✅ ISO, SOC 2, GDPR | Соответствие ключевым международным стандартам безопасности и защиты данных. |
| **Ценообразование** | ✅ Прозрачное | Чёткая тарификация по входным и выходным токенам. Скидки при массовом использовании и через провайдеров. |


# Google AI Studio и Vertex AI

## Общая характеристика

**Google AI Studio** — это точка входа для разработчиков к экосистеме моделей **Gemini API**. Здесь можно быстро запускать прототипы, работать с ключами доступа и Live API, тестировать инструменты и функции.

Когда же проект выходит за рамки экспериментов и требуется промышленное использование, в дело вступает **Vertex AI** — полнофункциональная платформа Google Cloud. Она обеспечивает полный цикл работы с моделями: от хранения данных и обучения до построения агентов, интеграции RAG-компонентов, управления безопасностью и MLOps.

Такое разделение создаёт понятную лестницу: от первых шагов в AI Studio до масштабного продакшен-решения в Vertex AI.

---

## API и уровни доступа

Google строит многоуровневую систему API, чтобы разработчик мог выбирать глубину взаимодействия с моделями.

**На низком уровне** доступны сами модели Gemini — от версии **2.x Pro** до облегчённых **Flash/Flash-Lite**. Они поддерживают мультимодальность и очень длинный контекст (до 1–2 млн токенов). Дополнительно открыты возможности генерации изображений и видео через **Imagen 4** и **Veo 3**, а также аудио через сервисы **Text-to-Speech**, **Speech-to-Text** и новую модель **Lyria** для музыки.

**На среднем уровне** появляется управление диалогом, вызов функций и использование инструментов. Здесь же доступно получение ответов через **Google Search**, работа с **Extensions API** (например, встроенный интерпретатор кода) и создание агентов через **Agent Builder/Agent Engine**. Для RAG-сценариев предусмотрены **Vector Search** (масштабируемая база векторных представлений) и **Search & Conversation** для поиска по корпоративным данным.

**На высоком уровне** платформа предлагает готовые сценарии: корпоративные ассистенты (Agentspace), преднастроенные коннекторы к CRM и системам поиска, а также дата-сторы для бизнес-применений.

---

## Инструменты разработчика

Google предлагает экосистему SDK и фреймворков. Для начала есть **Vertex AI Python SDK** и **Google Gen AI SDK**, охватывающие и AI Studio, и Vertex AI.

Для кастомизации моделей в Vertex AI поддерживается **supervised fine-tuning** (SFT) для Gemini 2.x, что позволяет дообучать их под собственные задачи. В чистом AI Studio fine-tuning временно недоступен, но для прототипов достаточно работы через промпты и API.

Особое внимание уделено **агентам**: Google развивает **Agent Engine** и **ADK (Agent Development Kit)**, совместимые со сторонними фреймворками.

Встроенный стек для RAG объединяет Vector Search, Search & Conversation и интеграции с BigQuery или AlloyDB. А для выполнения кода предусмотрено расширение **code-interpreter**, которое можно подключать как инструмент в диалоговой сессии.

Если же требуется работа в реальном времени — помогает **Live API**, обеспечивающий двунаправленные сессии со стримингом и tool use.

---

## Развёртывание

Vertex AI гибко подходит к инфраструктуре.

* **Облако (SaaS)**: стандартный режим — быстрый доступ к моделям с региональными или глобальными эндпоинтами.
* **Гибрид**: подключение к корпоративным данным через коннекторы, настройка приватности с помощью **VPC Service Controls** и **CMEK**.
* **On-premise/air-gapped**: через **Google Distributed Cloud** можно развернуть изолированную версию Vertex AI, включая генеративные модели.

---

## Экосистема и мультимодальность

Google делает ставку на мультимодальные возможности.

* **Imagen 4/Nano Banana** — для текст-ту-имидж генерации с улучшенной типографикой.
* **Veo 3** — для создания видео, включая поддержку разных форматов и синхронизацию аудио.
* **Lyria** и **Lyria RealTime** — для генерации музыки и аудио в Vertex AI Media Studio.
* Для речи доступны устойчивые сервисы **STT v2** и **TTS**.

Эти медиа-инструменты глубоко интегрированы в общую платформу и могут использоваться вместе с агентами и RAG-пайплайнами.

---

## Итог

**Google AI Studio и Vertex AI** образуют единую связку: первая часть отвечает за быстрые эксперименты, вторая — за масштабирование и продакшен.

Google предлагает не только доступ к моделям Gemini, но и целую экосистему инструментов — от RAG и агентов до мультимодальных генераторов и безопасных on-prem развертываний.

В результате разработчик получает платформу, которая может быть одинаково полезна и для старта прототипа, и для построения промышленного AI-решения с учётом требований бизнеса и безопасности.

# Характеристики Google AI Studio и Vertex AI

| Функция | Поддержка в Google AI Studio / Vertex AI | Описание |
|--------|----------------------------------------|--------|
| **Точка входа для разработчиков** | ✅ Google AI Studio | Удобный интерфейс для быстрого старта: прототипирование, тестирование моделей, управление API-ключами и Live API. |
| **Продакшен-платформа** | ✅ Vertex AI | Полнофункциональная платформа для промышленного внедрения: MLOps, безопасность, масштабирование, агенты, RAG. |
| **Модельная линейка Gemini** | ✅ Gemini 2.x Pro, Flash, Flash-Lite | Доступ к различным версиям Gemini: от мощных (Pro) до лёгких и быстрых (Flash/Lite). |
| **Контекстное окно** | ✅ До 1–2 млн токенов | Поддержка очень длинного контекста для работы с объёмными документами и сложными задачами. |
| **Мультимодальность** | ✅ Текст, изображения, аудио, видео | Поддержка мультимодальных входов и выходов: анализ и генерация на основе разных типов данных. |
| **Генерация изображений** | ✅ Imagen 4 / Imagen Nano Banana | Высококачественная генерация изображений по тексту с улучшенной типографикой и оптимизацией под веб. |
| **Генерация видео** | ✅ Veo 3 | Создание видео по текстовому описанию, включая поддержку различных форматов и синхронизацию аудио. |
| **Генерация музыки и аудио** | ✅ Lyria / Lyria RealTime | Модели для синтеза музыки и аудио, доступные в Vertex AI Media Studio. |
| **Речевые технологии** | ✅ STT v2, TTS | Точные сервисы распознавания речи (Speech-to-Text) и синтеза речи (Text-to-Speech). |
| **REST API** | ✅ Есть | Прямой доступ к моделям через HTTP-интерфейс. Поддерживается в AI Studio и Vertex AI. |
| **Live API (двунаправленный стриминг)** | ✅ Есть | Поддержка интерактивных сессий в реальном времени со стримингом и tool use. |
| **Streaming** | ✅ Есть | Потоковая передача ответов модели в режиме реального времени. |
| **Batch API** | ✅ Пакетные предсказания в Vertex AI | Поддержка массовой обработки запросов через пакетные задания (Batch Predictions). |
| **Function Calling / Tool Use** | ✅ Есть | Возможность описывать внешние инструменты, которые модель может вызывать в процессе диалога. |
| **Code Interpreter** | ✅ Расширение code-interpreter | Встроенный инструмент для выполнения Python-кода в изолированной среде (аналог OpenAI). |
| **RAG-стек** | ✅ Полный | Готовые компоненты: Vector Search (векторная база), Search & Conversation (поиск по документам), интеграции с BigQuery, AlloyDB. |
| **Vector Search** | ✅ Есть | Масштабируемая векторная база данных для хранения эмбеддингов и семантического поиска. |
| **Поиск по корпоративным данным** | ✅ Search & Conversation | Интеграция с внутренними источниками знаний: документы, базы данных, CRM. |
| **Агенты** | ✅ Agent Builder / Agent Engine / ADK | Инструменты для создания и развертывания AI-агентов, совместимые с LangChain и сторонними фреймворками. |
| **Extensions API** | ✅ Есть | Расширяемость платформы: подключение внешних инструментов и сервисов через API. |
| **Fine-tuning** | ✅ Supervised Fine-Tuning (SFT) в Vertex AI | Поддержка дообучения моделей Gemini 2.x на пользовательских данных. В AI Studio — временно недоступно. |
| **Промышленный MLOps** | ✅ Vertex AI | Полный цикл управления моделями: версионирование, мониторинг, деплой, CI/CD, эксперименты. |
| **Безопасность и соответствие** | ✅ ISO, SOC 2, GDPR, 152-ФЗ и др. | Соответствие ключевым международным и российским стандартам безопасности. |
| **VPC Service Controls** | ✅ Есть | Защита от утечек данных через изоляцию ресурсов в приватных виртуальных сетях. |
| **CMEK (Customer-Managed Encryption Keys)** | ✅ Есть | Возможность использовать собственные ключи шифрования для данных в Vertex AI. |
| **Развёртывание** | ✅ Облако (SaaS) | Стандартный режим: доступ к моделям через Google Cloud с глобальными и региональными эндпоинтами. |
| **Гибридные сценарии** | ✅ Есть | Интеграция с корпоративной инфраструктурой через коннекторы, VPC и CMEK. |
| **On-premise / Air-gapped** | ✅ Через Google Distributed Cloud | Возможность развёртывания изолированной версии Vertex AI в закрытом контуре (включая генеративные модели). |
| **Google Distributed Cloud** | ✅ Есть | Решение для развертывания Google Cloud в локальной или edge-инфраструктуре, включая полностью изолированные среды. |
| **SDK** | ✅ Vertex AI Python SDK, Google Gen AI SDK | Официальные SDK для Python, поддерживающие работу с Gemini, агентами, RAG и MLOps. |
| **Интеграция с BigQuery** | ✅ Есть | Прямая работа с данными из BigQuery: анализ, генерация отчётов, RAG. |
| **Консоль управления** | ✅ Есть (Google Cloud Console) | Удобный веб-интерфейс для управления ресурсами, моделями, ключами и безопасностью. |
| **Tracker и совместная работа** | ⚠️ Нет (аналог — Google Workspace) | Вместо Tracker используется Google Workspace (Docs, Sheets, Meet) для командной работы. |
| **Мониторинг и метрики** | ✅ Cloud Monitoring | Полноценный сервис для сбора, хранения и визуализации метрик моделей и инфраструктуры. |