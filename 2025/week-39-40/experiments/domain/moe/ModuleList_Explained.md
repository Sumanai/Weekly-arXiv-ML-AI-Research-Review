# üìö nn.ModuleList: –ü–æ–ª–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –¥–ª—è MoE Layer

> **–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª**: –ì–ª—É–±–æ–∫–æ–µ –ø–æ–≥—Ä—É–∂–µ–Ω–∏–µ –≤ —Ä–∞–±–æ—Ç—É `nn.ModuleList` –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ Mixture-of-Experts –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã.

---

## üéØ –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

1. [–í–≤–µ–¥–µ–Ω–∏–µ](#–≤–≤–µ–¥–µ–Ω–∏–µ)
2. [–ü—Ä–æ–±–ª–µ–º–∞: –ü–æ—á–µ–º—É –æ–±—ã—á–Ω—ã–π —Å–ø–∏—Å–æ–∫ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç?](#–ø—Ä–æ–±–ª–µ–º–∞-–ø–æ—á–µ–º—É-–æ–±—ã—á–Ω—ã–π-—Å–ø–∏—Å–æ–∫-–Ω–µ-—Ä–∞–±–æ—Ç–∞–µ—Ç)
3. [–†–µ—à–µ–Ω–∏–µ: nn.ModuleList](#—Ä–µ—à–µ–Ω–∏–µ-nnmodulelist)
4. [–ü–æ—à–∞–≥–æ–≤–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏](#–ø–æ—à–∞–≥–æ–≤–æ–µ-–æ–±—ä—è—Å–Ω–µ–Ω–∏–µ-–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏)
5. [–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤ –ø–∞–º—è—Ç–∏](#–≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è-–≤-–ø–∞–º—è—Ç–∏)
6. [–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ forward()](#–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ-–≤-forward)
7. [–ö–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã](#–∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ-–≤–æ–ø—Ä–æ—Å—ã)
8. [–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã](#–ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ-–ø—Ä–∏–º–µ—Ä—ã)
9. [–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –¥—Ä—É–≥–∏–º–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞–º–∏](#—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ-—Å-–¥—Ä—É–≥–∏–º–∏-–∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞–º–∏)
10. [–ß–∞—Å—Ç—ã–µ –æ—à–∏–±–∫–∏ –∏ —Ä–µ—à–µ–Ω–∏—è](#—á–∞—Å—Ç—ã–µ-–æ—à–∏–±–∫–∏-–∏-—Ä–µ—à–µ–Ω–∏—è)
11. [–°—Å—ã–ª–∫–∏ –∏ —Ä–µ—Å—É—Ä—Å—ã](#—Å—Å—ã–ª–∫–∏-–∏-—Ä–µ—Å—É—Ä—Å—ã)

---

## –í–≤–µ–¥–µ–Ω–∏–µ

–í –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ **Mixture-of-Experts (MoE)** –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º **–Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π** (—ç–∫—Å–ø–µ—Ä—Ç–æ–≤), –∫–æ—Ç–æ—Ä—ã–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç —Ä–∞–∑–Ω—ã–µ —á–∞—Å—Ç–∏ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —ç—Ç–∏—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –≤ PyTorch –Ω—É–∂–µ–Ω —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä ‚Äî **`nn.ModuleList`**.

### –ö–ª—é—á–µ–≤–æ–π –≤–æ–ø—Ä–æ—Å
**–ó–∞—á–µ–º –Ω—É–∂–µ–Ω `nn.ModuleList`, –µ—Å–ª–∏ –≤ Python —É–∂–µ –µ—Å—Ç—å –æ–±—ã—á–Ω—ã–π `list`?**

–û—Ç–≤–µ—Ç: PyTorch –¥–æ–ª–∂–µ–Ω **–æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã** –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –¥–ª—è:
- –í—ã—á–∏—Å–ª–µ–Ω–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
- –ü–µ—Ä–µ–Ω–æ—Å–∞ –Ω–∞ GPU/CPU
- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è/–∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏
- –ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞

–û–±—ã—á–Ω—ã–π Python —Å–ø–∏—Å–æ–∫ —ç—Ç–æ–≥–æ **–Ω–µ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç**.

---

## –ü—Ä–æ–±–ª–µ–º–∞: –ü–æ—á–µ–º—É –æ–±—ã—á–Ω—ã–π —Å–ø–∏—Å–æ–∫ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç?

### ‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥

```python
class BrokenMoELayer(nn.Module):
    def __init__(self, hidden_size=512, num_experts=8):
        super().__init__()

        # ‚ö†Ô∏è –û–®–ò–ë–ö–ê: –û–±—ã—á–Ω—ã–π Python —Å–ø–∏—Å–æ–∫!
        self.experts = [
            Expert(hidden_size, intermediate_size=2048)
            for _ in range(num_experts)
        ]
```

### –ß—Ç–æ –ø–æ–π–¥—ë—Ç –Ω–µ —Ç–∞–∫?

#### 1. **–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–µ —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É—é—Ç—Å—è**
```python
moe = BrokenMoELayer()
print(list(moe.parameters()))  # ‚ùå –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫! –≠–∫—Å–ø–µ—Ä—Ç—ã –Ω–µ –≤–∏–¥–Ω—ã PyTorch
```

#### 2. **–ì—Ä–∞–¥–∏–µ–Ω—Ç—ã –Ω–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è—é—Ç—Å—è**
```python
output = moe(x)
loss = output.sum()
loss.backward()  # ‚ùå –ì—Ä–∞–¥–∏–µ–Ω—Ç—ã –∫ —ç–∫—Å–ø–µ—Ä—Ç–∞–º –ù–ï –¥–æ–π–¥—É—Ç!
```

#### 3. **–ú–æ–¥–µ–ª—å –Ω–µ –ø–µ—Ä–µ–Ω–æ—Å–∏—Ç—Å—è –Ω–∞ GPU**
```python
moe = moe.to('cuda')  # ‚ùå –≠–∫—Å–ø–µ—Ä—Ç—ã –æ—Å—Ç–∞—é—Ç—Å—è –Ω–∞ CPU!
x = x.to('cuda')
output = moe(x)  # üí• RuntimeError: Input and weight are on different devices
```

#### 4. **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ/–∑–∞–≥—Ä—É–∑–∫–∞ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç**
```python
torch.save(moe.state_dict(), 'model.pt')  # ‚ùå –í–µ—Å–∞ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –ù–ï —Å–æ—Ö—Ä–∞–Ω—è—Ç—Å—è!
```

### üîç –ü–æ—á–µ–º—É —Ç–∞–∫ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç?

PyTorch **–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ—Ç** —Ç–æ–ª—å–∫–æ —Ç–µ –∞—Ç—Ä–∏–±—É—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ —è–≤–ª—è—é—Ç—Å—è:
- `nn.Module` (–æ–¥–∏–Ω –º–æ–¥—É–ª—å)
- `nn.ModuleList` (—Å–ø–∏—Å–æ–∫ –º–æ–¥—É–ª–µ–π)
- `nn.ModuleDict` (—Å–ª–æ–≤–∞—Ä—å –º–æ–¥—É–ª–µ–π)
- `nn.Sequential` (–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–¥—É–ª–µ–π)

–û–±—ã—á–Ω—ã–π Python `list` ‚Äî —ç—Ç–æ **–Ω–µ PyTorch –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä**, –ø–æ—ç—Ç–æ–º—É –æ–Ω –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç—Å—è.

---

## –†–µ—à–µ–Ω–∏–µ: nn.ModuleList

### ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥

```python
class SimpleMoELayer(nn.Module):
    def __init__(self, hidden_size=512, num_experts=8):
        super().__init__()

        # ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û: nn.ModuleList!
        self.experts = nn.ModuleList([
            Expert(hidden_size, intermediate_size=2048)
            for _ in range(num_experts)
        ])
```

### –ß—Ç–æ —ç—Ç–æ –¥–∞—ë—Ç?

#### 1. **–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≤–∏–¥–Ω—ã PyTorch**
```python
moe = SimpleMoELayer()
print(len(list(moe.parameters())))  # ‚úÖ –í—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã Router + 8 —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
```

#### 2. **–ì—Ä–∞–¥–∏–µ–Ω—Ç—ã —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è—é—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ**
```python
output = moe(x)
loss = output.sum()
loss.backward()  # ‚úÖ –ì—Ä–∞–¥–∏–µ–Ω—Ç—ã –¥–æ—Ö–æ–¥—è—Ç –¥–æ –≤—Å–µ—Ö 8 —ç–∫—Å–ø–µ—Ä—Ç–æ–≤!

for expert in moe.experts:
    print(expert.ffn.w1.grad)  # ‚úÖ –ì—Ä–∞–¥–∏–µ–Ω—Ç—ã –µ—Å—Ç—å!
```

#### 3. **–ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–Ω–æ—Å–∏—Ç—Å—è –Ω–∞ GPU —Ü–µ–ª–∏–∫–æ–º**
```python
moe = moe.to('cuda')  # ‚úÖ –í—Å–µ 8 —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –ø–µ—Ä–µ–Ω–æ—Å—è—Ç—Å—è –Ω–∞ GPU
x = x.to('cuda')
output = moe(x)  # ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
```

#### 4. **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ/–∑–∞–≥—Ä—É–∑–∫–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç**
```python
torch.save(moe.state_dict(), 'model.pt')  # ‚úÖ –í—Å–µ –≤–µ—Å–∞ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è
moe.load_state_dict(torch.load('model.pt'))  # ‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç
```

---

## –ü–æ—à–∞–≥–æ–≤–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏

–†–∞–∑–±–µ—Ä—ë–º –ø–æ—Å—Ç—Ä–æ—á–Ω–æ –∫–æ–¥ –∏–∑ `SimpleMoELayer`:

```python
self.experts = nn.ModuleList([
    Expert(hidden_size, intermediate_size, expert_dropout)
    for _ in range(num_experts)
])
```

### –®–∞–≥ 1: List Comprehension (–≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è —á–∞—Å—Ç—å)

```python
[Expert(hidden_size, intermediate_size, expert_dropout) for _ in range(num_experts)]
```

**–ß—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç:**
1. `range(num_experts)` ‚Üí `[0, 1, 2, 3, 4, 5, 6, 7]` (–¥–ª—è 8 —ç–∫—Å–ø–µ—Ä—Ç–æ–≤)
2. `for _ in range(...)` ‚Äî —Ü–∏–∫–ª; `_` –æ–∑–Ω–∞—á–∞–µ—Ç "–∏—Ç–µ—Ä–∞—Ç–æ—Ä –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è"
3. `Expert(...)` —Å–æ–∑–¥–∞—ë—Ç—Å—è **8 —Ä–∞–∑** —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
4. –†–µ–∑—É–ª—å—Ç–∞—Ç: **Python —Å–ø–∏—Å–æ–∫** –∏–∑ 8 –æ–±—ä–µ–∫—Ç–æ–≤ `Expert`

**–≠–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω—ã–π –∫–æ–¥ –±–µ–∑ list comprehension:**

```python
experts_list = []
for i in range(8):
    expert = Expert(
        hidden_size=512,
        intermediate_size=2048,
        dropout=0.0
    )
    experts_list.append(expert)
# experts_list = [Expert‚ÇÄ, Expert‚ÇÅ, Expert‚ÇÇ, ..., Expert‚Çá]
```

### –®–∞–≥ 2: –û–±—ë—Ä—Ç–∫–∞ –≤ nn.ModuleList

```python
self.experts = nn.ModuleList([...])
```

**–ß—Ç–æ –¥–µ–ª–∞–µ—Ç `nn.ModuleList`:**
1. –ü—Ä–∏–Ω–∏–º–∞–µ—Ç Python —Å–ø–∏—Å–æ–∫ –º–æ–¥—É–ª–µ–π
2. **–†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ—Ç** –∫–∞–∂–¥—ã–π –º–æ–¥—É–ª—å –∫–∞–∫ –ø–æ–¥–º–æ–¥—É–ª—å
3. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä, –∫–æ—Ç–æ—Ä—ã–π:
   - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é: `self.experts[3]`
   - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∏—Ç–µ—Ä–∞—Ü–∏—é: `for expert in self.experts`
   - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç `len()`: `len(self.experts)`
   - **–ù–ï –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç** `.append()` –ø–æ—Å–ª–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ (—Ç–æ–ª—å–∫–æ —á—Ç–µ–Ω–∏–µ)

### –®–∞–≥ 3: –í–∞–∂–Ω—ã–µ –¥–µ—Ç–∞–ª–∏

#### –ö–∞–∂–¥—ã–π —ç–∫—Å–ø–µ—Ä—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è **–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ**

```python
# –í—Å–µ —ç–∫—Å–ø–µ—Ä—Ç—ã –∏–º–µ—é—Ç –†–ê–ó–ù–´–ï –≤–µ—Å–∞!
moe = SimpleMoELayer(hidden_size=512, num_experts=8)

expert_0_weight = moe.experts[0].ffn.w1.weight
expert_1_weight = moe.experts[1].ffn.w1.weight

print(torch.allclose(expert_0_weight, expert_1_weight))  # ‚úÖ False ‚Äî –≤–µ—Å–∞ —Ä–∞–∑–Ω—ã–µ!
```

**–ü–æ—á–µ–º—É?** –ö–∞–∂–¥—ã–π `Expert(...)` –≤—ã–∑—ã–≤–∞–µ—Ç —Å–≤–æ—é –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é –≤–µ—Å–æ–≤ (Xavier, Kaiming –∏ —Ç.–¥.).

#### –≠–∫—Å–ø–µ—Ä—Ç—ã –∏–º–µ—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—É—é **–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É**, –Ω–æ —Ä–∞–∑–Ω—ã–µ **–ø–∞—Ä–∞–º–µ—Ç—Ä—ã**

```
–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (–æ–¥–∏–Ω–∞–∫–æ–≤–∞):
  Expert ‚Üí SwiGLU(512, 2048, 512) ‚Üí Dropout(0.0)

–ü–∞—Ä–∞–º–µ—Ç—Ä—ã (—Ä–∞–∑–Ω—ã–µ):
  Expert‚ÇÄ: w1, w2, w3 –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã —Å–ª—É—á–∞–π–Ω–æ
  Expert‚ÇÅ: w1, w2, w3 –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã —Å–ª—É—á–∞–π–Ω–æ (–¥—Ä—É–≥–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è!)
  ...
```

---

## –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤ –ø–∞–º—è—Ç–∏

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ SimpleMoELayer

```
SimpleMoELayer (nn.Module)
‚îÇ
‚îú‚îÄ‚îÄ self.hidden_size = 512              # –û–±—ã—á–Ω—ã–π –∞—Ç—Ä–∏–±—É—Ç (int)
‚îú‚îÄ‚îÄ self.num_experts = 8                # –û–±—ã—á–Ω—ã–π –∞—Ç—Ä–∏–±—É—Ç (int)
‚îú‚îÄ‚îÄ self.top_k = 2                      # –û–±—ã—á–Ω—ã–π –∞—Ç—Ä–∏–±—É—Ç (int)
‚îÇ
‚îú‚îÄ‚îÄ self.router ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          # –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥–º–æ–¥—É–ª—å
‚îÇ                            ‚îÇ
‚îÇ                            ‚îú‚îÄ‚Üí MoERouter (nn.Module)
‚îÇ                            ‚îÇ   ‚îú‚îÄ‚îÄ gate: nn.Linear(512, 8)
‚îÇ                            ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ weight: Tensor(8, 512)
‚îÇ                            ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ bias: Tensor(8)
‚îÇ                            ‚îÇ   ‚îî‚îÄ‚îÄ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: 4104
‚îÇ                            ‚îÇ
‚îî‚îÄ‚îÄ self.experts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          # –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥–º–æ–¥—É–ª—å (–∫–æ–Ω—Ç–µ–π–Ω–µ—Ä)
                             ‚îÇ
                             ‚îú‚îÄ‚Üí nn.ModuleList
                             ‚îÇ   ‚îÇ
                             ‚îÇ   ‚îú‚îÄ‚îÄ [0] Expert‚ÇÄ (nn.Module)
                             ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ffn: SwiGLU
                             ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ w1: nn.Linear(512, 2048)
                             ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ w2: nn.Linear(512, 2048)
                             ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ w3: nn.Linear(2048, 512)
                             ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dropout: nn.Dropout(0.0)
                             ‚îÇ   ‚îÇ
                             ‚îÇ   ‚îú‚îÄ‚îÄ [1] Expert‚ÇÅ (nn.Module)
                             ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ... (—Ç–∞ –∂–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞, –¥—Ä—É–≥–∏–µ –≤–µ—Å–∞)
                             ‚îÇ   ‚îÇ
                             ‚îÇ   ‚îú‚îÄ‚îÄ [2] Expert‚ÇÇ (nn.Module)
                             ‚îÇ   ‚ãÆ
                             ‚îÇ   ‚îî‚îÄ‚îÄ [7] Expert‚Çá (nn.Module)
                             ‚îÇ       ‚îî‚îÄ‚îÄ ... (—Ç–∞ –∂–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞, –¥—Ä—É–≥–∏–µ –≤–µ—Å–∞)
                             ‚îÇ
                             ‚îî‚îÄ‚îÄ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ —ç–∫—Å–ø–µ—Ä—Ç–∞—Ö: ~8.4M
```

### –ß—Ç–æ –≤–∏–¥–∏—Ç PyTorch –ø—Ä–∏ –≤—ã–∑–æ–≤–µ `.parameters()`?

```python
moe = SimpleMoELayer(hidden_size=512, num_experts=8)

for name, param in moe.named_parameters():
    print(name, param.shape)

# –í—ã–≤–æ–¥:
# router.gate.weight          torch.Size([8, 512])
# router.gate.bias            torch.Size([8])
# experts.0.ffn.w1.weight     torch.Size([2048, 512])
# experts.0.ffn.w1.bias       torch.Size([2048])
# experts.0.ffn.w2.weight     torch.Size([2048, 512])
# experts.0.ffn.w2.bias       torch.Size([2048])
# experts.0.ffn.w3.weight     torch.Size([512, 2048])
# experts.0.ffn.w3.bias       torch.Size([512])
# experts.1.ffn.w1.weight     torch.Size([2048, 512])
# experts.1.ffn.w1.bias       torch.Size([2048])
# ... (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ –¥–ª—è Expert‚ÇÇ...Expert‚Çá)
```

**–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ:**
- –ò–º–µ–Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤–∫–ª—é—á–∞—é—Ç –ø—Ä–µ—Ñ–∏–∫—Å `experts.0`, `experts.1` –∏ —Ç.–¥.
- –≠—Ç–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –Ω—É–º–µ—Ä–∞—Ü–∏—è –æ—Ç `nn.ModuleList`
- PyTorch **–≤–∏–¥–∏—Ç –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã** –±–ª–∞–≥–æ–¥–∞—Ä—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏

---

## –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ forward()

### –ö–∞–∫ Router –≤—ã–±–∏—Ä–∞–µ—Ç —ç–∫—Å–ø–µ—Ä—Ç–æ–≤

```python
def forward(self, hidden_states, training=True):
    # –®–∞–≥ 1: Router –≤—ã–±–∏—Ä–∞–µ—Ç top_k —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–æ–∫–µ–Ω–∞
    routing_weights, selected_experts, balance_loss = self.router(hidden_states, training)

    # routing_weights: (batch_size, seq_len, top_k=2)
    #   –ü—Ä–∏–º–µ—Ä –¥–ª—è —Ç–æ–∫–µ–Ω–∞ [0, 0]: [0.7, 0.3] ‚Äî –≤–µ—Å–∞ –¥–ª—è –¥–≤—É—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤

    # selected_experts: (batch_size, seq_len, top_k=2) dtype=long
    #   –ü—Ä–∏–º–µ—Ä –¥–ª—è —Ç–æ–∫–µ–Ω–∞ [0, 0]: [2, 5] ‚Äî –∏–Ω–¥–µ–∫—Å—ã —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ (Expert‚ÇÇ –∏ Expert‚ÇÖ)
```

### –ö–∞–∫ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è —Ç–æ–∫–µ–Ω—ã

```python
    # –®–∞–≥ 2: –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ —Ç–æ–∫–µ–Ω–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏ —ç–∫—Å–ø–µ—Ä—Ç–∞–º–∏
    batch_size, seq_len, hidden_size = hidden_states.shape
    output = torch.zeros_like(hidden_states)  # (batch_size, seq_len, hidden_size)

    for b in range(batch_size):
        for s in range(seq_len):
            token = hidden_states[b, s:s+1, :]  # (1, 1, hidden_size) ‚Äî –í–ê–ñ–ù–û: s:s+1!
            token_output = torch.zeros(1, 1, hidden_size)

            # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑ top_k=2 —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
            for k in range(self.top_k):
                # –ü–æ–ª—É—á–∞–µ–º –∏–Ω–¥–µ–∫—Å —ç–∫—Å–ø–µ—Ä—Ç–∞ (0-7)
                expert_idx = selected_experts[b, s, k].item()  # int: 0, 1, 2, ..., 7

                # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Å (0.0-1.0)
                weight = routing_weights[b, s, k].item()  # float: 0.7, 0.3, ...

                # –ü–æ–ª—É—á–∞–µ–º —ç–∫—Å–ø–µ—Ä—Ç –∏–∑ ModuleList –ø–æ –∏–Ω–¥–µ–∫—Å—É
                expert = self.experts[expert_idx]  # ‚úÖ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∫–∞–∫ –≤ –æ–±—ã—á–Ω–æ–º —Å–ø–∏—Å–∫–µ!

                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–∫–µ–Ω —ç–∫—Å–ø–µ—Ä—Ç–æ–º
                expert_output = expert(token)  # (1, 1, hidden_size)

                # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ
                token_output += weight * expert_output

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            output[b, s, :] = token_output.squeeze()  # (hidden_size,)

    # –®–∞–≥ 3: Residual connection
    output = output + hidden_states

    return output, balance_loss
```

### –ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã

#### 1. **–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è `self.experts[expert_idx]`**

```python
expert_idx = 5  # Router –≤—ã–±—Ä–∞–ª Expert‚ÇÖ
expert = self.experts[expert_idx]  # –ü–æ–ª—É—á–∞–µ–º Expert‚ÇÖ

# nn.ModuleList –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Å–ø–∏—Å–æ–∫:
self.experts[0]  # Expert‚ÇÄ
self.experts[7]  # Expert‚Çá
```

#### 2. **–ü–æ—á–µ–º—É `.item()` –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞?**

```python
expert_idx = selected_experts[b, s, k].item()  # Tensor(5) ‚Üí int(5)
```

**–ü—Ä–∏—á–∏–Ω–∞:** `selected_experts[b, s, k]` ‚Äî —ç—Ç–æ **0-–º–µ—Ä–Ω—ã–π —Ç–µ–Ω–∑–æ—Ä** (—Å–∫–∞–ª—è—Ä), –∞ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –Ω—É–∂–µ–Ω **Python int**.

```python
# ‚ùå –ù–µ —Ä–∞–±–æ—Ç–∞–µ—Ç:
expert = self.experts[selected_experts[b, s, k]]  # TypeError!

# ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç:
expert = self.experts[selected_experts[b, s, k].item()]  # int ‚Üí –∏–Ω–¥–µ–∫—Å
```

#### 3. **–ü–æ—á–µ–º—É `s:s+1`, –∞ –Ω–µ `s`?**

```python
token = hidden_states[b, s:s+1, :]  # ‚úÖ (1, 1, 512) ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å seq
# vs
token = hidden_states[b, s, :]      # ‚ùå (512,) ‚Äî —Ç–µ—Ä—è–µ—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å seq
```

**–ü—Ä–∏—á–∏–Ω–∞:** Expert –æ–∂–∏–¥–∞–µ—Ç –≤—Ö–æ–¥ —Ñ–æ—Ä–º—ã `(batch, seq, hidden)`. –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `[b, s, :]`, –ø–æ–ª—É—á–∏–º —Ñ–æ—Ä–º—É `(hidden,)`, —á—Ç–æ —Å–ª–æ–º–∞–µ—Ç forward pass.

---

## –ö–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã

–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–≤–æ—ë –ø–æ–Ω–∏–º–∞–Ω–∏–µ:

### –í–æ–ø—Ä–æ—Å 1
**–ß—Ç–æ –≤–µ—Ä–Ω—ë—Ç `len(self.experts)`?**

<details>
<summary>–û—Ç–≤–µ—Ç</summary>

`8` ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –≤ `nn.ModuleList`.

```python
moe = SimpleMoELayer(num_experts=8)
print(len(moe.experts))  # 8
```
</details>

---

### –í–æ–ø—Ä–æ—Å 2
**–í—Å–µ –ª–∏ —ç–∫—Å–ø–µ—Ä—Ç—ã –∏–º–µ—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –≤–µ—Å–∞ –ø–æ—Å–ª–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏?**

<details>
<summary>–û—Ç–≤–µ—Ç</summary>

**–ù–µ—Ç!** –ö–∞–∂–¥—ã–π `Expert` –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è **–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ** —Å —Ä–∞–∑–Ω—ã–º–∏ —Å–ª—É—á–∞–π–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏.

```python
expert_0 = moe.experts[0]
expert_1 = moe.experts[1]

# –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –æ–¥–∏–Ω–∞–∫–æ–≤–∞, –Ω–æ –≤–µ—Å–∞ —Ä–∞–∑–Ω—ã–µ:
print(expert_0.ffn.w1.weight)  # –°–ª—É—á–∞–π–Ω—ã–µ –≤–µ—Å–∞ A
print(expert_1.ffn.w1.weight)  # –°–ª—É—á–∞–π–Ω—ã–µ –≤–µ—Å–∞ B (‚â† A)
```
</details>

---

### –í–æ–ø—Ä–æ—Å 3
**–ß—Ç–æ –ø—Ä–æ–∏–∑–æ–π–¥—ë—Ç, –µ—Å–ª–∏ –∑–∞–º–µ–Ω–∏—Ç—å `nn.ModuleList` –Ω–∞ –æ–±—ã—á–Ω—ã–π `list`?**

<details>
<summary>–û—Ç–≤–µ—Ç</summary>

–ú–æ–¥–µ–ª—å **–Ω–µ –±—É–¥–µ—Ç –æ–±—É—á–∞—Ç—å—Å—è**:
- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –Ω–µ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É—é—Ç—Å—è
- –ì—Ä–∞–¥–∏–µ–Ω—Ç—ã –Ω–µ –¥–æ–π–¥—É—Ç –¥–æ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
- `.to(device)` –Ω–µ –ø–µ—Ä–µ–Ω–µ—Å—ë—Ç —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ/–∑–∞–≥—Ä—É–∑–∫–∞ –Ω–µ –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å

```python
# ‚ùå –°–ª–æ–º–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è:
self.experts = [Expert(...) for _ in range(8)]

# –ü—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏:
optimizer.step()  # –û–±–Ω–æ–≤—è—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã Router, —ç–∫—Å–ø–µ—Ä—Ç—ã –æ—Å—Ç–∞–Ω—É—Ç—Å—è –Ω–µ–∏–∑–º–µ–Ω–Ω—ã–º–∏!
```
</details>

---

### –í–æ–ø—Ä–æ—Å 4
**–ú–æ–∂–Ω–æ –ª–∏ –æ–±—Ä–∞—â–∞—Ç—å—Å—è –∫ —ç–∫—Å–ø–µ—Ä—Ç–∞–º –ø–æ –∏–Ω–¥–µ–∫—Å—É `self.experts[3]`?**

<details>
<summary>–û—Ç–≤–µ—Ç</summary>

**–î–∞!** `nn.ModuleList` –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Å–ø–∏—Å–æ–∫.

```python
third_expert = moe.experts[3]  # –ü–æ–ª—É—á–∞–µ–º Expert‚ÇÉ
output = third_expert(x)  # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
```

–¢–∞–∫–∂–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è:
- –ò—Ç–µ—Ä–∞—Ü–∏—è: `for expert in moe.experts:`
- –î–ª–∏–Ω–∞: `len(moe.experts)`
- –°—Ä–µ–∑—ã: `moe.experts[2:5]` (–ù–û —ç—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ã—á–Ω—ã–π —Å–ø–∏—Å–æ–∫, –Ω–µ ModuleList!)
</details>

---

### –í–æ–ø—Ä–æ—Å 5
**–ú–æ–∂–Ω–æ –ª–∏ –¥–æ–±–∞–≤–ª—è—Ç—å —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –≤ `nn.ModuleList` –ø–æ—Å–ª–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏?**

<details>
<summary>–û—Ç–≤–µ—Ç</summary>

**–ú–æ–∂–Ω–æ, –Ω–æ –ù–ï —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –≤ production.**

```python
# ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç, –Ω–æ —Ä–µ–¥–∫–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è:
moe.experts.append(Expert(512, 2048))  # –î–æ–±–∞–≤–ª—è–µ–º 9-–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞

# ‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º–∞: Router –æ–±—É—á–µ–Ω –Ω–∞ 8 —ç–∫—Å–ø–µ—Ä—Ç–æ–≤, –∞ —Ç–µ–ø–µ—Ä—å –∏—Ö 9!
# –ò–Ω–¥–µ–∫—Å—ã 0-7 –±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è, –∞ —ç–∫—Å–ø–µ—Ä—Ç 8 ‚Äî –Ω–µ—Ç.
```

**–ö–æ–≥–¥–∞ —ç—Ç–æ –ø–æ–ª–µ–∑–Ω–æ:**
- –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è (—Ä–µ–¥–∫–∏–π –∫–µ–π—Å)
- –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å transfer learning

**–û–±—ã—á–Ω–æ:** –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–æ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏.
</details>

---

## –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã

### –ü—Ä–∏–º–µ—Ä 1: –°–æ–∑–¥–∞–Ω–∏–µ –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ MoE Layer

```python
import torch
from experiments.domain.moe.moe_layer import SimpleMoELayer

# –°–æ–∑–¥–∞–Ω–∏–µ MoE Layer
moe = SimpleMoELayer(
    hidden_size=512,
    num_experts=8,
    top_k=2,
    intermediate_size=2048
)

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤: {len(moe.experts)}")  # 8
print(f"–¢–∏–ø –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞: {type(moe.experts)}")       # <class 'torch.nn.modules.container.ModuleList'>

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
total_params = sum(p.numel() for p in moe.parameters())
print(f"–í—Å–µ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {total_params:,}")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞
expert_0 = moe.experts[0]
print(f"–ü–µ—Ä–≤—ã–π —ç–∫—Å–ø–µ—Ä—Ç: {expert_0}")
print(f"–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {expert_0.ffn}")
```

### –ü—Ä–∏–º–µ—Ä 2: –ò—Ç–µ—Ä–∞—Ü–∏—è –ø–æ —ç–∫—Å–ø–µ—Ä—Ç–∞–º

```python
# –ò—Ç–µ—Ä–∞—Ü–∏—è –ø–æ –≤—Å–µ–º —ç–∫—Å–ø–µ—Ä—Ç–∞–º
for idx, expert in enumerate(moe.experts):
    num_params = sum(p.numel() for p in expert.parameters())
    print(f"Expert {idx}: {num_params:,} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")

# –í—ã–≤–æ–¥:
# Expert 0: 1,050,112 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
# Expert 1: 1,050,112 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
# Expert 2: 1,050,112 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
# ...
# Expert 7: 1,050,112 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
```

### –ü—Ä–∏–º–µ—Ä 3: –î–æ—Å—Ç—É–ø –∫ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞

```python
# –ü–æ–ª—É—á–∞–µ–º –≤–µ—Å–∞ –ø–µ—Ä–≤–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞
expert_0 = moe.experts[0]
w1_weight = expert_0.ffn.w1.weight  # (2048, 512)
w1_bias = expert_0.ffn.w1.bias      # (2048,)

print(f"W1 weight shape: {w1_weight.shape}")
print(f"W1 bias shape: {w1_bias.shape}")
print(f"W1 weight sample: {w1_weight[0, :5]}")  # –ü–µ—Ä–≤—ã–µ 5 –∑–Ω–∞—á–µ–Ω–∏–π
```

### –ü—Ä–∏–º–µ—Ä 4: Forward pass —Å –∞–Ω–∞–ª–∏–∑–æ–º

```python
# –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
x = torch.randn(2, 10, 512)  # (batch=2, seq=10, hidden=512)

# Forward pass
output, balance_loss = moe(x, training=True)

print(f"Input shape:  {x.shape}")        # (2, 10, 512)
print(f"Output shape: {output.shape}")   # (2, 10, 512)
print(f"Balance loss: {balance_loss.item():.6f}")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ residual connection
# Output ‚â† 0, –¥–∞–∂–µ –µ—Å–ª–∏ Router –æ–±–Ω—É–ª–∏–ª –≤–µ—Å–∞
print(f"Output is non-zero: {not torch.allclose(output, torch.zeros_like(output))}")  # True
```

### –ü—Ä–∏–º–µ—Ä 5: –ü–µ—Ä–µ–Ω–æ—Å –Ω–∞ GPU

```python
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–Ω–æ—Å–∞ –Ω–∞ GPU (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
if torch.cuda.is_available():
    moe = moe.to('cuda')
    x = x.to('cuda')

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ —ç–∫—Å–ø–µ—Ä—Ç—ã –Ω–∞ GPU
    for idx, expert in enumerate(moe.experts):
        device = next(expert.parameters()).device
        print(f"Expert {idx} –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ: {device}")

    # –í—ã–≤–æ–¥:
    # Expert 0 –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ: cuda:0
    # Expert 1 –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ: cuda:0
    # ...
    # Expert 7 –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ: cuda:0
```

### –ü—Ä–∏–º–µ—Ä 6: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞

```python
# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
torch.save(moe.state_dict(), 'moe_layer.pt')
print("–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")

# –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏
moe_new = SimpleMoELayer(hidden_size=512, num_experts=8, top_k=2)

# –ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤
moe_new.load_state_dict(torch.load('moe_layer.pt'))
print("–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–¥–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏
x = torch.randn(1, 5, 512)
out1, _ = moe(x, training=False)
out2, _ = moe_new(x, training=False)

print(f"–í—ã—Ö–æ–¥—ã –∏–¥–µ–Ω—Ç–∏—á–Ω—ã: {torch.allclose(out1, out2)}")  # True
```

---

## –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –¥—Ä—É–≥–∏–º–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞–º–∏

PyTorch –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –¥–ª—è –º–æ–¥—É–ª–µ–π:

### nn.ModuleList vs nn.Sequential

| –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ | `nn.ModuleList` | `nn.Sequential` |
|----------------|-----------------|-----------------|
| **–ü–æ—Ä—è–¥–æ–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è** | –ü—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π (–≤—ã –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç–µ) | –°—Ç—Ä–æ–≥–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π |
| **–î–æ—Å—Ç—É–ø –ø–æ –∏–Ω–¥–µ–∫—Å—É** | ‚úÖ –î–∞ (`self.experts[3]`) | ‚úÖ –î–∞ (`self.layers[2]`) |
| **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π forward** | ‚ùå –ù–µ—Ç (–ø–∏—à–µ—Ç–µ —Å–∞–º–∏) | ‚úÖ –î–∞ (–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ) |
| **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ** | –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –≤–µ—Ç–≤–∏, —É—Å–ª–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ | –õ–∏–Ω–µ–π–Ω—ã–µ —Å—Ç–µ–∫–∏ (ResNet, VGG) |

**–ü—Ä–∏–º–µ—Ä nn.Sequential:**
```python
# –õ–∏–Ω–µ–π–Ω—ã–π —Å—Ç–µ–∫ —Å–ª–æ—ë–≤
self.layers = nn.Sequential(
    nn.Linear(512, 1024),
    nn.ReLU(),
    nn.Linear(1024, 512)
)

# Forward –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π:
output = self.layers(x)  # x ‚Üí Linear ‚Üí ReLU ‚Üí Linear
```

**–ü–æ—á–µ–º—É MoE –∏—Å–ø–æ–ª—å–∑—É–µ—Ç ModuleList, –∞ –Ω–µ Sequential?**
- –≠–∫—Å–ø–µ—Ä—Ç—ã —Ä–∞–±–æ—Ç–∞—é—Ç **–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ**, –∞ –Ω–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ
- –ö–∞–∂–¥—ã–π —Ç–æ–∫–µ–Ω –∏–¥—ë—Ç —Ç–æ–ª—å–∫–æ –∫ **top_k —ç–∫—Å–ø–µ—Ä—Ç–∞–º**, –∞ –Ω–µ –∫–æ –≤—Å–µ–º
- –ù—É–∂–µ–Ω **–ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π –¥–æ—Å—Ç—É–ø** –ø–æ –∏–Ω–¥–µ–∫—Å—É: `self.experts[expert_idx]`

---

### nn.ModuleList vs nn.ModuleDict

| –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ | `nn.ModuleList` | `nn.ModuleDict` |
|----------------|-----------------|-----------------|
| **–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è** | –ü–æ —á–∏—Å–ª–æ–≤–æ–º—É –∏–Ω–¥–µ–∫—Å—É: `[0], [1]` | –ü–æ —Å—Ç—Ä–æ–∫–æ–≤–æ–º—É –∫–ª—é—á—É: `['encoder'], ['decoder']` |
| **–ü–æ—Ä—è–¥–æ–∫** | –£–ø–æ—Ä—è–¥–æ—á–µ–Ω (–∫–∞–∫ —Å–ø–∏—Å–æ–∫) | –£–ø–æ—Ä—è–¥–æ—á–µ–Ω (Python 3.7+) |
| **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ** | –û–¥–Ω–æ—Ä–æ–¥–Ω—ã–µ –º–æ–¥—É–ª–∏ (8 —ç–∫—Å–ø–µ—Ä—Ç–æ–≤) | –†–∞–∑–Ω–æ—Ä–æ–¥–Ω—ã–µ –º–æ–¥—É–ª–∏ (encoder + decoder) |

**–ü—Ä–∏–º–µ—Ä nn.ModuleDict:**
```python
# –°–ª–æ–≤–∞—Ä—å —Ä–∞–∑–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
self.components = nn.ModuleDict({
    'encoder': TransformerEncoder(...),
    'decoder': TransformerDecoder(...),
    'head': nn.Linear(512, vocab_size)
})

# –î–æ—Å—Ç—É–ø –ø–æ –∫–ª—é—á—É:
encoded = self.components['encoder'](x)
decoded = self.components['decoder'](encoded)
output = self.components['head'](decoded)
```

**–ü–æ—á–µ–º—É MoE –∏—Å–ø–æ–ª—å–∑—É–µ—Ç ModuleList, –∞ –Ω–µ ModuleDict?**
- –≠–∫—Å–ø–µ—Ä—Ç—ã **–æ–¥–Ω–æ—Ä–æ–¥–Ω—ã** (–æ–¥–∏–Ω–∞–∫–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞)
- –ò–Ω–¥–µ–∫—Å—ã **—á–∏—Å–ª–æ–≤—ã–µ** (0-7), –∞ –Ω–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ ('expert_relu', 'expert_conv')
- Router –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç **—á–∏—Å–ª–æ–≤—ã–µ –∏–Ω–¥–µ–∫—Å—ã**, —É–¥–æ–±–Ω–æ –¥–ª—è –ø—Ä—è–º–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞

---

### –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞

| –°—Ü–µ–Ω–∞—Ä–∏–π | –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä | –ü—Ä–∏–º–µ—Ä |
|----------|-----------|--------|
| –õ–∏–Ω–µ–π–Ω—ã–π —Å—Ç–µ–∫ —Å–ª–æ—ë–≤ | `nn.Sequential` | ResNet block, MLP |
| –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –æ–¥–Ω–æ—Ä–æ–¥–Ω—ã–µ –º–æ–¥—É–ª–∏ | `nn.ModuleList` | MoE experts, multi-head attention |
| –†–∞–∑–Ω–æ—Ä–æ–¥–Ω—ã–µ –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã | `nn.ModuleDict` | Encoder-Decoder, multi-task heads |
| –£—Å–ª–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ —Å –≤–µ—Ç–≤–ª–µ–Ω–∏—è–º–∏ | `nn.ModuleList` + custom forward | Neural Architecture Search, AdaIN |

---

## –ß–∞—Å—Ç—ã–µ –æ—à–∏–±–∫–∏ –∏ —Ä–µ—à–µ–Ω–∏—è

### –û—à–∏–±–∫–∞ 1: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –æ–±—ã—á–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞

**–ü—Ä–æ–±–ª–µ–º–∞:**
```python
self.experts = [Expert(...) for _ in range(8)]  # ‚ùå
```

**–°–∏–º–ø—Ç–æ–º:**
```python
RuntimeError: Input and weight are on different devices
# –∏–ª–∏
# –ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–∞–µ—Ç—Å—è (loss –Ω–µ —É–º–µ–Ω—å—à–∞–µ—Ç—Å—è)
```

**–†–µ—à–µ–Ω–∏–µ:**
```python
self.experts = nn.ModuleList([Expert(...) for _ in range(8)])  # ‚úÖ
```

---

### –û—à–∏–±–∫–∞ 2: –ó–∞–±—ã–ª–∏ `.item()` –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏

**–ü—Ä–æ–±–ª–µ–º–∞:**
```python
expert_idx = selected_experts[b, s, k]  # Tensor(5)
expert = self.experts[expert_idx]  # ‚ùå TypeError!
```

**–°–∏–º–ø—Ç–æ–º:**
```python
TypeError: list indices must be integers or slices, not Tensor
```

**–†–µ—à–µ–Ω–∏–µ:**
```python
expert_idx = selected_experts[b, s, k].item()  # int(5)
expert = self.experts[expert_idx]  # ‚úÖ
```

---

### –û—à–∏–±–∫–∞ 3: –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–∞

**–ü—Ä–æ–±–ª–µ–º–∞:**
```python
token = hidden_states[b, s, :]  # ‚ùå (512,) –≤–º–µ—Å—Ç–æ (1, 1, 512)
expert_output = expert(token)   # RuntimeError: Expected 3D tensor
```

**–°–∏–º–ø—Ç–æ–º:**
```python
RuntimeError: Expected 3D input (got 1D input)
```

**–†–µ—à–µ–Ω–∏–µ:**
```python
token = hidden_states[b, s:s+1, :]  # ‚úÖ (1, 1, 512)
expert_output = expert(token)
```

---

### –û—à–∏–±–∫–∞ 4: –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ ModuleList –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è Router

**–ü—Ä–æ–±–ª–µ–º–∞:**
```python
# –û–±—É—á–∏–ª–∏ Router –Ω–∞ 8 —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
moe = SimpleMoELayer(num_experts=8)
train(moe)

# –ü–æ—Ç–æ–º –¥–æ–±–∞–≤–∏–ª–∏ 9-–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞
moe.experts.append(Expert(...))  # ‚ö†Ô∏è Router –Ω–µ –∑–Ω–∞–µ—Ç –ø—Ä–æ –∏–Ω–¥–µ–∫—Å 8!
```

**–°–∏–º–ø—Ç–æ–º:**
- Expert 8 –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è (Router –≤—ã–¥–∞—ë—Ç —Ç–æ–ª—å–∫–æ –∏–Ω–¥–µ–∫—Å—ã 0-7)

**–†–µ—à–µ–Ω–∏–µ:**
- –§–∏–∫—Å–∏—Ä—É–π—Ç–µ `num_experts` –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
- –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ ‚Äî –ø–µ—Ä–µ–æ–±—É—á–∏—Ç–µ Router

---

### –û—à–∏–±–∫–∞ 5: –°—Ä–µ–∑—ã –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç –æ–±—ã—á–Ω—ã–π —Å–ø–∏—Å–æ–∫

**–ü—Ä–æ–±–ª–µ–º–∞:**
```python
first_three = moe.experts[:3]  # ‚ùå –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç list, –∞ –Ω–µ nn.ModuleList!
first_three = first_three.to('cuda')  # AttributeError!
```

**–°–∏–º–ø—Ç–æ–º:**
```python
AttributeError: 'list' object has no attribute 'to'
```

**–†–µ—à–µ–Ω–∏–µ:**
–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∏—Ç–µ—Ä–∞—Ü–∏—é –∏–ª–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é –ø–æ –æ–¥–Ω–æ–º—É:
```python
for expert in moe.experts[:3]:
    expert.to('cuda')  # ‚úÖ
```

---

## –°—Å—ã–ª–∫–∏ –∏ —Ä–µ—Å—É—Ä—Å—ã

### –û—Ñ–∏—Ü–∏–∞–ª—å–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è PyTorch
- [nn.ModuleList](https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html)
- [nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)
- [nn.ModuleDict](https://pytorch.org/docs/stable/generated/torch.nn.ModuleDict.html)

### –°–≤—è–∑–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞
- `experiments/domain/moe/moe_layer.py` ‚Äî —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è SimpleMoELayer
- `experiments/domain/moe/router.py` ‚Äî MoE Router —Å Top-K gating
- `experiments/domain/moe/expert.py` ‚Äî Expert Network (SwiGLU)
- `experiments/domain/moe/test/test_moe_layer.py` ‚Äî —Ç–µ—Å—Ç—ã –¥–ª—è MoE Layer

### –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã
- [PyTorch Container Modules](https://pytorch.org/docs/stable/nn.html#containers)
- [Mixture-of-Experts Papers](https://arxiv.org/abs/2202.09368)
- [Qwen3 Technical Report](https://arxiv.org/abs/2409.12186)

---

## üéì –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

**–ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã:**

1. ‚úÖ **`nn.ModuleList` –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω** –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –º–æ–¥—É–ª–µ–π –≤ PyTorch
2. ‚úÖ **–û–±—ã—á–Ω—ã–π Python `list` –ù–ï —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ—Ç** –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –ª–æ–º–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ
3. ‚úÖ **–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç** –∫–∞–∫ –≤ –æ–±—ã—á–Ω–æ–º —Å–ø–∏—Å–∫–µ: `self.experts[idx]`
4. ‚úÖ **–ö–∞–∂–¥—ã–π –º–æ–¥—É–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ** —Å —Ä–∞–∑–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏
5. ‚úÖ **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ MoE**: Router ‚Üí –∏–Ω–¥–µ–∫—Å—ã ‚Üí –¥–æ—Å—Ç—É–ø –∫ —ç–∫—Å–ø–µ—Ä—Ç–∞–º ‚Üí –æ–±—Ä–∞–±–æ—Ç–∫–∞

**–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:**

–ü—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å–æ —Å–ø–∏—Å–∫–æ–º –º–æ–¥—É–ª–µ–π –≤ PyTorch **–≤—Å–µ–≥–¥–∞** –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:
- `nn.ModuleList` ‚Äî –¥–ª—è –æ–¥–Ω–æ—Ä–æ–¥–Ω—ã—Ö –º–æ–¥—É–ª–µ–π (—ç–∫—Å–ø–µ—Ä—Ç—ã, —Å–ª–æ–∏ attention)
- `nn.Sequential` ‚Äî –¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π (ResNet block)
- `nn.ModuleDict` ‚Äî –¥–ª—è –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ (encoder/decoder)

**–ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ** –æ–±—ã—á–Ω—ã–π Python `list` –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è `nn.Module`!

---

<div align="center">

**Made with ‚ù§Ô∏è for Deep Learning Education**

[‚¨Ü –í–µ—Ä–Ω—É—Ç—å—Å—è –∫ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é](#-—Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ)

</div>
