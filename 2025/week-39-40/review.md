# От GPT-2 к gpt-oss: анализ достижений архитектуры
> И как они выглядят на фоне Qwen3

5 августа, 2025 года OpenAI выпустила новые модели LLM с открытым весом: gpt-oss-120b и gpt-oss-20b, первые модели с открытым весом после GPT-2 в 2019 году. И да, благодаря некоторым умным оптимизациям их можно запускать локально (но об этом позже).

Впервые со времён GPT-2 компания OpenAI представила крупную модель с полностью открытыми весами. Ранее выпущенные модели GPT демонстрировали масштабируемость архитектуры Transformer. Выпуск ChatGPT 2022 года сделал эти модели популярными, продемонстрировав конкретную полезность для задач письма и обработки знаний (а затем и программирования). Теперь же они поделились долгожданной моделью весов, и архитектура обладает некоторыми интересными деталями.

Последние несколько дней я посвятил изучению кода и технических отчетов, чтобы извлечь из них наиболее интересные детали. (Всего несколько дней спустя OpenAI также анонсировала GPT-5, о котором я кратко расскажу в контексте моделей gpt-oss в конце этой статьи.)

Ниже представлен краткий обзор содержания статьи. Для удобства навигации рекомендую использовать оглавление слева на странице статьи.

- Сравнение архитектуры модели с GPT-2

- Оптимизация MXFP4 для размещения моделей gpt-oss на отдельных графических процессорах

- Компромисс между шириной и глубиной (gpt-oss против Qwen3)

- Смещение внимания и его провалы

- Тесты и сравнения с GPT-5

Надеюсь, вы найдете это познавательным!