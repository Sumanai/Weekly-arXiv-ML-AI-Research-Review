### Приблизительный план

1. Аннотация (RU/ENG)
2. Введение и мотивация
3. Связанные работы
4. Постановка задачи и границы
5. Данные и сбор
6. Предобработка ЭЭГ
7. Сборка датасета и разметка
8. Метод: обзор пайплайна и модели
9. Обучение и настройка
10. Инференс и интерфейс вывода
11. Оценка и протокол экспериментов
12. Результаты
13. Воспроизводимость и артефакты
14. Ограничения и угрозы валидности
15. Заключение и будущее
16. Ссылки
17. Приложения

---

# EEG→Text: воспроизводимый конвейер восстановления семантики внутренней речи из сигналов ЭЭГ (обзорная версия)

**Автор(ы):** *Вербецкий Эдуард Игоревич*
**Аффилиация:** *Московский авиационный института (национальный исследовательский университет)*
**Контакт:** *verbasik@gmail.com*
**Версия препринта:** v1 (обзорная)

---

## Аннотация

Мы представляем воспроизводимый end‑to‑end конвейер «EEG → Текст» для исследования внутренней речи в парадигмах *read* и *imagine*. Конвейер стандартизует предобработку (очистка артефактов, референс, ICA‑автомаркировка, адаптивная вейвлет‑фильтрация, нормализация), вводит явные контракты данных и поддерживает многоцелевое обучение энкодера ЭЭГ (CNN+Transformer) с векторной квантизацией и вспомогательными головами (грубые семантические категории, домен *read/imagine*, реконструкция сигнала). Мы формализуем задачу как retrieval по фиксированному словарю фраз и параллельную классификацию категорий/домена, описываем протоколы оценки (within‑session, cross‑session, cross‑subject), меры против утечек, набор метрик (Top‑k, MRR, macro‑F1/BA, калибровка доверия) и структуру «репро‑пакета» для воспроизводимости результатов. Предварительные эксперименты указывают на потенциал VQ и многоцелевой оптимизации к стабилизации и интерпретируемости представлений; в следующих версиях планируется систематическое сравнение с сильными бейзлайнами и перенос между сессиями и субъектами.

---

## 1. Введение и мотивация

Восстановление семантики внутренней речи по неинвазивным сигналам мозга — ключевая задача для BCI‑систем, когнитивной нейронауки и мультимодальных интерфейсов. В отличие от инвазивных методов, ЭЭГ безопасна и доступна, но страдает низким отношением сигнал/шум и межсубъектной вариабельностью. Мы предлагаем практичный конвейер от сырых EDF‑файлов до инференса модели, ориентированный на воспроизводимость, стандартизованные форматы и прозрачную оценку.

**Вклад работы (summary):**

1. Формализуем постановку «EEG→Text retrieval» по фиксированному словарю фраз с параллельной классификацией грубых категорий и домена (*read/imagine*).
2. Описываем стандартизованный пайплайн предобработки с anti‑leakage практиками.
3. Представляем архитектуру энкодера ЭЭГ (CNN+Transformer) с VQ и многоцелевой оптимизацией (контрастивная + классификационные + реконструкция).
4. Фиксируем протоколы оценки (within / cross‑session / cross‑subject), метрики и статистические тесты.
5. Публикуем «репро‑пакет»: код, конфиги, фиксированные версии и чекпоинты (структура и инструкции).

---

## 2. Связанные работы (обзорно)

**Воображаемая речь на ЭЭГ.** Работы по распознаванию/классификации слогов, слов и категорий внутренней речи с использованием классических и глубоких архитектур.
**Контрастивное обучение «мозг↔семантика».** Подходы к выравниванию мозговых и текстовых представлений, retrieval‑формулировки, индексация кандидатов.
**Векторная квантизация в биосигналах.** Использование VQ для дискретизации скрытых представлений, анализ перплексии и стабильности кодбука.
(Полные ссылки будут добавлены в версию v2, см. раздел «Ссылки».)

---

## 3. Постановка задачи и границы применимости

Пусть $x\in\mathbb{R}^{C\times T}$ — отрезок ЭЭГ ($C$ каналов, $T$ отсчётов). Требуется:

* (a) **Retrieval** по словарю фраз $\mathcal{Y}=\{y_1,\dots,y_N\}$: найти топ‑$k$ кандидатов по счёту $s(f_\theta(x), g(y))$;
* (b) **классификация** грубой семантической категории $c\in\{1,\dots,K\}$;
* (c) **классификация домена** $d\in\{\text{read},\text{imagine}\}$.

Здесь $f_\theta$ — энкодер ЭЭГ. $g(\cdot)$ — замороженное текстовое отображение фразы в векторное пространство (используется **только** на стороне индекса/оценки сходства, см. anti‑leakage). Фиксируем **корпус фраз** и карту $\texttt{phrase}\to\texttt{coarse}$ до начала обучения и оценки.

**Сценарии оценки:**

* **within‑session:** обучение/оценка в рамках одной сессии субъекта (разные триалы);
* **cross‑session:** обучение в одной сессии, оценка — в другой сессии того же субъекта;
* **cross‑subject:** leave‑one‑subject‑out (LOSO) и/или адаптация ≤5% данных субъекта.

**Ограничения:** не рассматриваем OOD‑фразы вне словаря, синтез аудио/текста и онлайновую адаптацию в v1.

---

## 4. Данные и предобработка

**Вход:** сырые EDF‑файлы с маркировкой эпох *read/imagine* и привязкой фраз.
**Предобработка (fit‑on‑train per‑fold):**

1. Подавление сетевых и мышечных артефактов;
2. ре‑референс и автоматическая очистка;
3. ICA с авто‑детекцией компонент (мигание/ЭМГ/др.), исключение компонент — параметры сохраняются из **train**;
4. Адаптивная вейвлет‑фильтрация;
5. Нормализация/скалирование по статистикам **train**;
6. Нарезка на эпохи с фиксированным окном $[t_0, t_0+\Delta]$, без использования пост‑событийной информации вне окна.

**Контроль утечек:** ни одна операция не подгоняется на val/test; конвейер сохраняет параметры и применяет их неизменно.

---

## 5. Сборка датасета и контракты данных

* Валидация форматов, выравнивание каналов и метаданных.
* Привязка фраз к эпохам, карта $\texttt{phrase}\to\texttt{coarse}$ фиксируется (хэшируется).
* Экспорт в обучающий формат (например, `HDF5/Parquet + JSON`‑манифест).
* **Запрет семантического fallback**, использующего текстовый энкодер, совпадающий или родственый энкодеру модели. Если fallback применяется — метка помечается как «низкой уверенности», проводится оценка уровня шума.

---

## 6. Модель и обучение (обзорно)

**Энкодер ЭЭГ:** CNN‑stem для локально‑частотных признаков → Transformer‑энкодер по времени → дискретизация VQ (кодбук размером $M$) → агрегирование представления $z_q$.

**Вспомогательные головы:**
1. coarse‑классификатор; 
2. домен *read/imagine*; 
3. реконструктор сигнала (декодер).

**Контрастивное выравнивание:** между $z_q$ и $g(y)$, где $g$ — заморожен и обучением **не затрагивается**.

**Сводная функция потерь:**
$\mathcal{L} = \lambda_{con}\, \mathcal{L}_{NT\text{-}Xent} + \lambda_{coarse}\, \text{CE}_{coarse} + \lambda_{dom}\, \text{CE}_{dom} + \lambda_{rec}\, \|\hat{x}-x\|_2^2 + \lambda_{VQ}\, \mathcal{L}_{VQ}.$
Весовые коэффициенты $\lambda$ подбираются на валидации (grid/ASHA), без доступа к тесту.

**Диагностика VQ:** перплексия кодбука, распределение частот кодов, «живость» кодов, влияние $\beta$ (commitment) / размера кодбука.

---

## 7. Инференс и калибровка доверия

* Нормировка векторов, сходство $s(\cdot,\cdot)$ — косинус/ dot‑product, индекс кандидатов (например, FAISS).
* Возврат топ‑$k$ фраз с оценками.
* Калибровка доверия: temperature scaling/Platt по валидации, отчёт ECE и reliability‑кривая.

---

## 8. Протокол оценки и метрики

**Сплиты:** within‑session / cross‑session / cross‑subject (LOSO). Все предобработчики, скейлеры, ICA, пороги — fit‑on‑train per‑fold.
**Метрики (retrieval):** Top‑1/5/10, MRR, Recall\@k, nDCG\@k (опционально) + 95% CI (бутстрэп по триалам).
**Метрики (классификация):** accuracy, macro‑F1, balanced accuracy; матрицы ошибок.
**Калибровка:** ECE/ACE, Brier.
**Статистика:** пермутационный тест против случайного ранжирования и между моделями/абляциями.

**Бейзлайны:**

* Random;
* частотно‑полосные признаки + линейная модель/логрег;
* EEGNet / ShallowFBCSPNet;
* наш без‑VQ вариант;
* наш полный вариант.

**Абляции:** −VQ, −Recon, −AuxHeads, −Contrastive.

---

## 9. Результаты (предварительно, обзорно)

В v1 приводим качественные иллюстрации (t‑SNE/UMAP $z_q$ vs текстовые эмбеддинги, распределения кодбука), примеры top‑k выдачи, confusion‑матрицы по coarse/домену и reliability‑кривые. Численные таблицы по всем метрикам и сплитам будут расширены в v2 вместе с CI и сравнениями бейзлайнов/абляций.

---

## 10. Воспроизводимость и пакет артефактов

* **Окружение:** `conda env.yml` или `Dockerfile`, фиксация версий/seed, `requirements.txt`.
* **Конфигурации:** Hydra‑конфиги (`configs/`), `Makefile`/`invoke` для сценариев.
* **Данные:** скрипты загрузки/валидации, манифест и хэши словаря фраз/маппинга.
* **Обучение/оценка:** `train.py`, `eval.py`, `ablation.py`, `baseline.py`.
* **Индексация:** скрипт сборки индекса кандидатов; фиксация версий текстового энкодера.
* **Логи/артефакты:** DVC (`dvc.yaml`) или эквивалент, чекпоинты, конфиги, отчёты.
* **MODEL\_CARD.md:** назначение, ограничения, риски, области применения.

---

## 11. Ограничения

* Небольшое количество субъектов и вариативность межсубъектного переноса.
* Возможный шум в разметке фраз, отсутствие OOD‑оценки.
* Отсутствие онлайн‑адаптации и real‑time экспериментов в v1.

---

## 12. Практическая ценность и применения

Воспроизводимый каркас полезен для исследований внутренней речи, прототипирования BCI‑интерфейсов, а также как компонент мультимодальных систем «мозг↔компьютер». Единые контракты данных и стандартизованные шаги обработки упрощают сравнение моделей и накопление результатов.

---

## 13. Заключение и планы

Мы представили системный конвейер «EEG→Text» с акцентом на воспроизводимость и прозрачную оценку. В ближайших версиях: 

1. Полные таблицы результатов со статистикой и CI; 
2. Cильные бейзлайны и абляции; 
3. Перенос между сессиями и субъектами; 
4. Расширенная калибровка доверия и VQ‑диагностика.

---

## Благодарности

*Здесь — благодарности коллегам, лаборатории и участникам сбора данных.*

## Ссылки

*(будут добавлены в v2; в v1 оставляем обзорный характер без углублённой библиографии)*

---

### Приложение A. Anti‑leakage чек‑лист

* Fit всех предобработчиков/скейлеров/ICA/вейвлет‑порогов — **только на train per‑fold**.
* Гиперпараметры подбираются на **validation**, не на test.
* Текстовый энкодер для индекса/разметки **не обучается** на ваших данных и не совпадает с используемым в модели; при совпадении — удалить семантический fallback.
* Индекс и словарь фраз фиксируются до обучения (хэшируются).
* Проверка time‑leak: строгое временное окно инференса, без доступа к пост‑событийным сигналам.

### Приложение B. Диагностика VQ

* Перплексия и «живость» кодов, частотные распределения.
* Влияние размера кодбука и $\beta$ на качество и интерпретацию.
* Примеры паттернов кодов, связанных с coarse/доменом.

### Приложение C. Структура «репро‑пакета» (пример)

```
repo/
  ├─ env.yml | Dockerfile
  ├─ configs/
  ├─ data/
  │   └─ manifests/, hashes/
  ├─ src/
  │   ├─ preprocess/
  │   ├─ dataset/
  │   ├─ models/
  │   ├─ train.py  eval.py  ablation.py  baseline.py
  ├─ index/
  ├─ artifacts/  logs/
  ├─ MODEL_CARD.md  README.md  LICENSE
```

### Приложение D. Карточка модели (MODEL\_CARD.md, краткий шаблон)

**Назначение.** Retrieval по словарю фраз и классификация coarse/домена из ЭЭГ.
**Данные.** Источник, протокол сборки, согласия.
**Обучение.** Архитектура, лоссы, гиперпараметры.
**Оценка.** Сплиты, метрики, CI.
**Ограничения.** Области, где модель ненадёжна.
**Этика и риск.** Конфиденциальность, допустимые применения.
**Контакты.** Поддержка и связь.
