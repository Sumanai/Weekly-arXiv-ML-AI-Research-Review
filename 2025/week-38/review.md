### Приблизительный планЛадно

1. Аннотация (RU/ENG)
2. Введение и мотивация
3. Связанные работы
4. Постановка задачи и границы
5. Данные и сбор
6. Предобработка ЭЭГ
7. Сборка датасета и разметка
8. Метод: обзор пайплайна и модели
9. Обучение и настройка
10. Инференс и интерфейс вывода
11. Оценка и протокол экспериментов
12. Результаты
13. Воспроизводимость и артефакты
14. Ограничения и угрозы валидности
15. Заключение и будущее
16. Ссылки
17. Приложения

---

# Аннотация

Декодирование семантического содержания по ЭЭГ затруднено низким SNR, межсубъектной/межсессионной вариативностью и доменным разрывом между чтением и воображаемой речью. Мы представляем воспроизводимый энд-ту-энд конвейер «EEG → Текст», покрывающий путь от сырых EDF-записей до интерпретируемых выходов: топ-k кандидатных фраз, крупноклассовой (coarse) категории и домена (read/imagine) с оценками уверенности. Конвейер стандартизует предобработку (ресэмплинг, PREP, AutoReject, ICA с автоматической маркировкой, адаптивная вейвлет-фильтрация, нормализация), формирует единые эпохи и контракты данных; модель включает энкодер ЭЭГ (CNN+Transformer с векторной квантизацией), семантический декодер, вспомогательные головы для классификации домена/категорий и модуль реконструкции ЭЭГ.

На рабочем подмножестве датасета Chisco — корпуса воображаемой речи с 39 семантическими категориями и парадигмой «чтение→воображение» (5.0 с + 3.3 с) — мы использовали 8 008 эпизодов (read = 4 030, imagine = 3 978), 122-канальные записи и 4 103 уникальные фразы. В домене *imagine* метод достиг **Top-5 Accuracy = 0.8288** и **MRR = 0.6340**; точность крупноклассовой классификации составила **1.0000**. Средняя косинусная близость между квантованными ЭЭГ-эмбеддингами и текстовыми эмбеддингами составила **0.5856**. Результаты указывают, что стандартизованные контракты данных и многоцелевое обучение с VQ улучшают переносимость и стабильность декодирования «EEG → Текст» в условиях доменного разрыва. Код, конфигурации и артефакты оценки сопровождают результаты для воспроизводимости.

---

# Введение

**Контекст и значимость.**
ЭЭГ с миллисекундным разрешением остаётся доступным и перспективным инструментом для BCI и исследования внутренней/воображаемой речи. В отличие от инвазивных подходов к восстановлению речи, ЭЭГ-декодирование адресует сценарии для здоровых пользователей и практические BCI-приложения. Однако низкий SNR, артефакты, выраженная межсубъектная/межсессионная вариативность и доменный разрыв между условиями *read* и *imagine* делают задачу восстановления смысла по ЭЭГ особенно сложной.

**Состояние области и разрыв.**
Новейшие «натуралистические» парадигмы и корпусные подходы в BCI смещают фокус от стимул-зависимых протоколов к более жизненным задачам декодирования содержания. Для воображаемой речи заметным шагом стал датасет **Chisco**: высокоплотные записи трёх участников с длительными сессиями (> 900 мин. на человека), 6 681 предложением и **39 семантическими категориями**, где каждый триал содержит фазу чтения (5 000 мс) и последующую фазу воображаемой речи (3 300 мс). Этот протокол ограничивает свободную фантазию и повышает SNR; при этом задача остаётся нетривиальной из-за отличий нейронных представлений чтения и воображения. Несмотря на прогресс, сопоставимость результатов между работами часто страдает из-за разнородной предобработки, неявных контрактов форматов и неполных протоколов оценки; влияние многоцелевого обучения и векторной квантизации на переносимость «EEG → Текст» изучено недостаточно.

**Цель, исследовательские вопросы и гипотезы.**
Мы рассматриваем задачу «EEG → Текст» как **воспроизводимый конвейер** с интерпретируемыми выходами (топ-k фраз, категория, домен, confidence). Формулируем вопросы: 
- **RQ1** — повышают ли стандартизованные контракты данных (эпохи, формы тензоров, соглашения имён) устойчивость и сопоставимость декодирования? 
- **RQ2** — даёт ли **многоцелевое обучение** (семантическое выравнивание, классификация домена/категорий, реконструкция ЭЭГ) выигрыш против single-task, особенно в домене *imagine*? 
- **RQ3** — способствует ли **векторная квантизация** (VQ) формированию более «семантично выровненного» кодового пространства и росту Top-k/MRR?

**Наш вклад.**
1. Представляем документированный **энд-ту-энд конвейер** от EDF до инференса, включающий стандартизованную предобработку (ресэмплинг, PREP, AutoReject, ICA-автомаркировка, адаптивная вейвлет-фильтрация, нормализация) и **явные контракты данных** (эпохи, формы, каталожные соглашения).
2. Предлагаем **архитектуру** с энкодером ЭЭГ (CNN+Transformer) и **векторной квантизацией**, семантическим декодером и вспомогательными головами для домена/категорий и **реконструкция ЭЭГ** как регуляризатор.
3. Вводим **протокол оценки**: для фраз — Top-k Accuracy и MRR; для категорий/домена — accuracy; фиксируем split и публикуем конфигурации/чекпоинты/логи для повторяемости.
4. Демонстрируем **предварительные результаты** на рабочем подмножестве Chisco: в домене *imagine* достигаем **Top-5 = 0.8288** и **MRR = 0.6340** при средней косинусной близости **0.5856** между квантованными ЭЭГ-эмбеддингами и текстовыми представлениями; наблюдаем 16.0% использование кодбука (41/256). Эти результаты указывают на пользу стандартизованных контрактов и многоцелевой оптимизации; дальнейшая работа включает сравнение с сильными базовыми линиями и межсубъектный перенос.

**Краткий обзор подхода и структура статьи.**
Высокоуровнево наш конвейер состоит из: 
1. Стандартизованной предобработки и унифицированного эпохирования; 
2. Декларативных контрактов данных и экспорта в форматы, удобные для обучения; 
3. Многоцелевого обучения с VQ и реконструкцией; 
4. Инференса, возвращающего топ-k фраз, категорию и домен с оценками уверенности. 
