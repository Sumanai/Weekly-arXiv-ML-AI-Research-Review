### Приблизительный план

1. Аннотация (RU/ENG)
2. Введение и мотивация
3. Связанные работы
4. Постановка задачи и границы
5. Данные и сбор
6. Предобработка ЭЭГ
7. Сборка датасета и разметка
8. Метод: обзор пайплайна и модели
9. Обучение и настройка
10. Инференс и интерфейс вывода
11. Оценка и протокол экспериментов
12. Результаты
13. Воспроизводимость и артефакты
14. Ограничения и угрозы валидности
15. Заключение и будущее
16. Ссылки
17. Приложения

---

# EEG→Text: воспроизводимый конвейер восстановления семантики внутренней речи из сигналов ЭЭГ (обзорная версия)

**Автор(ы):** *Вербецкий Эдуард Игоревич*

**Аффилиация:** *Московский авиационный института (национальный исследовательский университет)*

**Контакт:** *verbasik@gmail.com*

**Версия препринта:** v1 (обзорная)

---

## Аннотация

Мы представляем воспроизводимый end‑to‑end конвейер «EEG → Текст» для исследования внутренней речи в парадигмах *read* и *imagine*. Конвейер стандартизует предобработку (очистка артефактов, референс, ICA‑автомаркировка, адаптивная вейвлет‑фильтрация, нормализация), вводит явные контракты данных и поддерживает многоцелевое обучение энкодера ЭЭГ (CNN+Transformer) с векторной квантизацией и вспомогательными головами (грубые семантические категории, домен *read/imagine*, реконструкция сигнала). Мы формализуем задачу как retrieval по фиксированному словарю фраз и параллельную классификацию категорий/домена, описываем протоколы оценки (within‑session, cross‑session, cross‑subject), меры против утечек, набор метрик (Top‑k, MRR, macro‑F1/BA, калибровка доверия) и структуру «репро‑пакета» для воспроизводимости результатов. Предварительные эксперименты указывают на потенциал VQ и многоцелевой оптимизации к стабилизации и интерпретируемости представлений; в следующих версиях планируется систематическое сравнение с сильными бейзлайнами и перенос между сессиями и субъектами.

---

## 1. Введение и мотивация

Восстановление семантики внутренней речи по неинвазивным сигналам мозга — ключевая задача для BCI‑систем, когнитивной нейронауки и мультимодальных интерфейсов. В отличие от инвазивных методов, ЭЭГ безопасна и доступна, но страдает низким отношением сигнал/шум и межсубъектной вариабельностью. Мы предлагаем практичный конвейер от сырых EDF‑файлов до инференса модели, ориентированный на воспроизводимость, стандартизованные форматы и прозрачную оценку.

**Вклад работы (summary):**

1. Формализуем постановку «EEG→Text retrieval» по фиксированному словарю фраз с параллельной классификацией грубых категорий и домена (*read/imagine*).
2. Описываем стандартизованный пайплайн предобработки с anti‑leakage практиками.
3. Представляем архитектуру энкодера ЭЭГ (CNN+Transformer) с VQ и многоцелевой оптимизацией (контрастивная + классификационные + реконструкция).
4. Фиксируем протоколы оценки (within / cross‑session / cross‑subject), метрики и статистические тесты.
5. Публикуем «репро‑пакет»: код, конфиги, фиксированные версии и чекпоинты (структура и инструкции).

---

## 2. Связанные работы (обзорно)

**Воображаемая речь на ЭЭГ.** Работы по распознаванию/классификации слогов, слов и категорий внутренней речи с использованием классических и глубоких архитектур.
**Контрастивное обучение «мозг↔семантика».** Подходы к выравниванию мозговых и текстовых представлений, retrieval‑формулировки, индексация кандидатов.
**Векторная квантизация в биосигналах.** Использование VQ для дискретизации скрытых представлений, анализ перплексии и стабильности кодбука.
(Полные ссылки будут добавлены в версию v2, см. раздел «Ссылки».)

---

## 3. Постановка задачи и границы применимости

Пусть $x\in\mathbb{R}^{C\times T}$ — отрезок ЭЭГ ($C$ каналов, $T$ отсчётов). Требуется:

* (a) **Retrieval** по словарю фраз $\mathcal{Y}=\{y_1,\dots,y_N\}$: найти топ‑$k$ кандидатов по счёту $s(f_\theta(x), g(y))$;
* (b) **классификация** грубой семантической категории $c\in\{1,\dots,K\}$;
* (c) **классификация домена** $d\in\{\text{read},\text{imagine}\}$.

Здесь $f_\theta$ — энкодер ЭЭГ. $g(\cdot)$ — замороженное текстовое отображение фразы в векторное пространство (используется **только** на стороне индекса/оценки сходства, см. anti‑leakage). Фиксируем **корпус фраз** и карту $\texttt{phrase}\to\texttt{coarse}$ до начала обучения и оценки.

**Сценарии оценки:**

* **within‑session:** обучение/оценка в рамках одной сессии субъекта (разные триалы);
* **cross‑session:** обучение в одной сессии, оценка — в другой сессии того же субъекта;
* **cross‑subject:** leave‑one‑subject‑out (LOSO) и/или адаптация ≤5% данных субъекта.

**Ограничения:** не рассматриваем OOD‑фразы вне словаря, синтез аудио/текста и онлайновую адаптацию в v1.

---

## 4. Данные и предобработка

В качестве исходного материала используются сырые записи ЭЭГ в формате EDF с аппаратными метками событий и привязкой каждой эпохи к конкретной фразе. Для унификации обработки мы фиксируем частоту дискретизации на уровне 500 Гц, используем согласованный монтаж и стабилизируем перечень рабочих каналов после исключения артефактных и вспомогательных (например, EOG). В каждом файле дополнительно сохраняется служебная метаинформация: идентификаторы субъекта, сессии и прогона, упорядоченный список имён каналов, хэш-сигнатура монтажа, сведения о «плохих» каналах, если таковые выявлены на этапе сбора.

Предобработка выстраивается как последовательный конвейер, цель которого — повысить отношение сигнал/шум и обеспечить воспроизводимость дальнейших шагов обучения. Сначала применяется полосовая фильтрация с пропусканием диапазона 0.5–50 Гц, затем подавляются сетевые гармоники на частоте 50 или 60 Гц и их кратные. Чтобы снять систематические смещения и аномальные электроды, используется пакет PREP: выполняется ре-референс, детектируются шумные каналы (включая RANSAC‑интерполяции), а решения по исправлению фиксируются. Все параметры PREP обучаются строго на обучающем подмножестве данных текущего фолда и затем неизменными воспроизводятся на валидации и тесте.

Разметка событий извлекается из аппаратного канала триггера и сопоставляется со списком фраз, после чего записи сегментируются в два непересекающихся окна: для домена read — от 0 до 5 секунд и для домена imagine — от 5 до 8.3 секунд. Базовая коррекция не применяется, а использование пост‑событийной информации вне заданного окна исключается. Для очистки выбросов и восстановления испорченных проб применяем AutoReject: пороги оцениваются только на обучающих эпохах, журналы и параметры порогов сохраняются, к остальным разбиениям применяется чистая трансформация без подгонки.

Следующий этап — независимые компоненты. Мы обучаем ICA на обучающем подмножестве (при необходимости раздельно для read и imagine), автоматически маркируем компоненты с помощью IClabel и исключаем не‑мозговые источники (мигания, ЭМГ и т. п.). В артефакты предобработки сохраняются матрицы смешивания и обратного преобразования, список исключённых компонент и полный журнал решений. Далее на валидации и тесте используется ровно то же преобразование без переобучения. Для повышения качества сигнала поверх этого применяется адаптивная вейвлет‑фильтрация (семейство Добеши, мягкий трешолдинг), причём выбор семейства и уровня разложения фиксируется по обучающему множеству и протоколируется для воспроизводимости.

Нормализация выполняется в одном из двух режимов. В локальном режиме каждая эпоха масштабируется по каналам с использованием собственных средних и стандартных отклонений, что является детерминированной процедурой без обучения на тесте. В глобальном режиме статистики по каналам оцениваются на обучении текущего фолда, сериализуются и затем применяются неизменно к валидационным и тестовым данным. При необходимости используется робастная версия с межквартильным размахом. На всех шагах формируются отчёты контроля качества: доля интерполированных каналов, остаточная сетевая мощность, распределения канал‑специфических средних и дисперсий, число исключённых компонент ICA, параметры вейвлет‑фильтрации. Все артефакты снабжаются хэшами и версиями библиотек.

Наконец, сводное правило контроля утечек: любые операции, параметры которых оцениваются по данным (PREP, AutoReject, ICA, глобальная нормализация, выбор параметров вейвлет‑фильтрации), обучаются исключительно на train внутри фолда и далее применяются как неизменяемые преобразования. Сегментация эпох жёстко ограничена заданными интервалами, что исключает появление информации из будущего относительно центра события.

---

## 5. Сборка датасета и контракты данных

Сборка датасета подчиняется принципу «контрактов данных», позволяющему однозначно восстанавливать и проверять состояние каждого примера. Для каждой эпохи формируется машинно‑читаемый манифест, в котором фиксируются идентификаторы субъекта, сессии и прогона, порядковый номер эпохи, домен (read или imagine), исходная фраза и её категориальная метка, границы окна по времени, частота дискретизации, упорядоченный список каналов и хэш монтажа, а также ссылки на все артефакты предобработки (решения PREP, параметры AutoReject, файлы ICA, состояние нормализатора, параметры вейвлет‑фильтра). Помимо этого, манифест содержит хэш полезной нагрузки (например, SHA‑256 массива признаков), версию кода и временную метку создания, что позволяет воспроизводить эксперименты и проверять целостность выгрузок.

Мы поддерживаем два комплементарных формата хранения. Формат FIF используется как эталонное представление эпох с полным набором метаданных, параллельно для обучения сохраняются компактные контейнеры в PKL, HDF5 или Parquet с тензорами признаков (float32) и ссылками на артефакты. Каталожная структура единообразна для всех субъектов и сессий: отдельные директории отведены под эталонные эпохи, итоговые пакеты для обучения, артефакты предобработки, производные признаки и журналы контроля качества.

Привязка фраз к эпохам осуществляется строго до обучения модели и опирается на статичную карту сопоставления «фраза → грубая категория», снабжённую собственным хэшем. Допускаются два режима соответствия: точное совпадение после нормализации строки и высокопороговое нестрогое совпадение (fuzzy). Использование семантического поиска по эмбеддингам как инструмента «доделки» разметки по умолчанию отключено, поскольку вносит в метки модельные предположения. Если такой режим всё же применяется для исследовательского анализа, каждое соответствие помечается пониженной уверенностью и либо исключается из обучающей выборки, либо анализируется отдельно с оценкой доли шумных меток и их влияния на итоговые метрики.

Для сценариев разбиения на обучающие, валидационные и тестовые множества мы предоставляем явные списки индексов эпох для within‑session, cross‑session и cross‑subject (LOSO), а также связанный набор артефактов, обученных на обучающем подмножестве. Структура таких описаний может храниться в файлах split.yaml, где помимо индексов указываются пути к сериализованным решениям PREP, AutoReject и ICA, состоянию нормализатора и параметрам вейвлет‑фильтра. Загрузка датасета сопровождается автоматической верификацией совместимости: проверяются число и порядок каналов, хэш монтажа, хэш карты меток, режим нормализации и границы временного окна. При несовпадениях применяется строгая политика отказа либо заранее задокументированная процедура адаптации.

Для удобства обучения глубинных моделей дополнительно поддерживается экспорт в формат, совместимый с PyTorch: для каждого домена хранится последовательность тензоров (C, T), список словарей меток (включая текст фразы, идентификатор категории и степень уверенности) и исходные длины до возможного паддинга, а в разделе метаданных фиксируются частота дискретизации, число каналов, хэш монтажа, маска каналов, режим нормализации, хэши состояний и версия кода. Все артефакты и манифесты снабжаются контрольными суммами и версионностью, а к каждому релизу датасета прилагается краткий журнал изменений и проверочные хэши контрольных подвыборок.

---

## 6. Модель и обучение (обзорно)

**Энкодер ЭЭГ:** CNN‑stem для локально‑частотных признаков → Transformer‑энкодер по времени → дискретизация VQ (кодбук размером $M$) → агрегирование представления $z_q$.

**Вспомогательные головы:**
1. coarse‑классификатор; 
2. домен *read/imagine*; 
3. реконструктор сигнала (декодер).

**Контрастивное выравнивание:** между $z_q$ и $g(y)$, где $g$ — заморожен и обучением **не затрагивается**.

**Сводная функция потерь:**
$\mathcal{L} = \lambda_{con}\, \mathcal{L}_{NT\text{-}Xent} + \lambda_{coarse}\, \text{CE}_{coarse} + \lambda_{dom}\, \text{CE}_{dom} + \lambda_{rec}\, \|\hat{x}-x\|_2^2 + \lambda_{VQ}\, \mathcal{L}_{VQ}.$
Весовые коэффициенты $\lambda$ подбираются на валидации (grid/ASHA), без доступа к тесту.

**Диагностика VQ:** перплексия кодбука, распределение частот кодов, «живость» кодов, влияние $\beta$ (commitment) / размера кодбука.

---

## 7. Инференс и калибровка доверия

* Нормировка векторов, сходство $s(\cdot,\cdot)$ — косинус/ dot‑product, индекс кандидатов (например, FAISS).
* Возврат топ‑$k$ фраз с оценками.
* Калибровка доверия: temperature scaling/Platt по валидации, отчёт ECE и reliability‑кривая.

---

## 8. Протокол оценки и метрики

**Сплиты:** within‑session / cross‑session / cross‑subject (LOSO). Все предобработчики, скейлеры, ICA, пороги — fit‑on‑train per‑fold.
**Метрики (retrieval):** Top‑1/5/10, MRR, Recall\@k, nDCG\@k (опционально) + 95% CI (бутстрэп по триалам).
**Метрики (классификация):** accuracy, macro‑F1, balanced accuracy; матрицы ошибок.
**Калибровка:** ECE/ACE, Brier.
**Статистика:** пермутационный тест против случайного ранжирования и между моделями/абляциями.

**Бейзлайны:**

* Random;
* частотно‑полосные признаки + линейная модель/логрег;
* EEGNet / ShallowFBCSPNet;
* наш без‑VQ вариант;
* наш полный вариант.

**Абляции:** −VQ, −Recon, −AuxHeads, −Contrastive.

---

## 9. Результаты (предварительно, обзорно)

В v1 приводим качественные иллюстрации (t‑SNE/UMAP $z_q$ vs текстовые эмбеддинги, распределения кодбука), примеры top‑k выдачи, confusion‑матрицы по coarse/домену и reliability‑кривые. Численные таблицы по всем метрикам и сплитам будут расширены в v2 вместе с CI и сравнениями бейзлайнов/абляций.

---

## 10. Воспроизводимость и пакет артефактов

* **Окружение:** `conda env.yml` или `Dockerfile`, фиксация версий/seed, `requirements.txt`.
* **Конфигурации:** Hydra‑конфиги (`configs/`), `Makefile`/`invoke` для сценариев.
* **Данные:** скрипты загрузки/валидации, манифест и хэши словаря фраз/маппинга.
* **Обучение/оценка:** `train.py`, `eval.py`, `ablation.py`, `baseline.py`.
* **Индексация:** скрипт сборки индекса кандидатов; фиксация версий текстового энкодера.
* **Логи/артефакты:** DVC (`dvc.yaml`) или эквивалент, чекпоинты, конфиги, отчёты.
* **MODEL\_CARD.md:** назначение, ограничения, риски, области применения.

---

## 11. Ограничения

* Небольшое количество субъектов и вариативность межсубъектного переноса.
* Возможный шум в разметке фраз, отсутствие OOD‑оценки.
* Отсутствие онлайн‑адаптации и real‑time экспериментов в v1.

---

## 12. Практическая ценность и применения

Воспроизводимый каркас полезен для исследований внутренней речи, прототипирования BCI‑интерфейсов, а также как компонент мультимодальных систем «мозг↔компьютер». Единые контракты данных и стандартизованные шаги обработки упрощают сравнение моделей и накопление результатов.

---

## 13. Заключение и планы

Мы представили системный конвейер «EEG→Text» с акцентом на воспроизводимость и прозрачную оценку. В ближайших версиях: 

1. Полные таблицы результатов со статистикой и CI; 
2. Cильные бейзлайны и абляции; 
3. Перенос между сессиями и субъектами; 
4. Расширенная калибровка доверия и VQ‑диагностика.

---

## Благодарности

*Здесь — благодарности коллегам, лаборатории и участникам сбора данных.*

## Ссылки

*(будут добавлены в v2; в v1 оставляем обзорный характер без углублённой библиографии)*

---

### Приложение A. Anti‑leakage чек‑лист

* Fit всех предобработчиков/скейлеров/ICA/вейвлет‑порогов — **только на train per‑fold**.
* Гиперпараметры подбираются на **validation**, не на test.
* Текстовый энкодер для индекса/разметки **не обучается** на ваших данных и не совпадает с используемым в модели; при совпадении — удалить семантический fallback.
* Индекс и словарь фраз фиксируются до обучения (хэшируются).
* Проверка time‑leak: строгое временное окно инференса, без доступа к пост‑событийным сигналам.

### Приложение B. Диагностика VQ

* Перплексия и «живость» кодов, частотные распределения.
* Влияние размера кодбука и $\beta$ на качество и интерпретацию.
* Примеры паттернов кодов, связанных с coarse/доменом.

### Приложение C. Структура «репро‑пакета» (пример)

```
repo/
  ├─ env.yml | Dockerfile
  ├─ configs/
  ├─ data/
  │   └─ manifests/, hashes/
  ├─ src/
  │   ├─ preprocess/
  │   ├─ dataset/
  │   ├─ models/
  │   ├─ train.py  eval.py  ablation.py  baseline.py
  ├─ index/
  ├─ artifacts/  logs/
  ├─ MODEL_CARD.md  README.md  LICENSE
```

### Приложение D. Карточка модели (MODEL\_CARD.md, краткий шаблон)

**Назначение.** Retrieval по словарю фраз и классификация coarse/домена из ЭЭГ.
**Данные.** Источник, протокол сборки, согласия.
**Обучение.** Архитектура, лоссы, гиперпараметры.
**Оценка.** Сплиты, метрики, CI.
**Ограничения.** Области, где модель ненадёжна.
**Этика и риск.** Конфиденциальность, допустимые применения.
**Контакты.** Поддержка и связь.
