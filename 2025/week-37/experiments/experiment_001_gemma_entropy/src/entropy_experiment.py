"""
–ö—Ä–∞—Å–∏–≤—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —ç–Ω—Ç—Ä–æ–ø–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤ –º–æ–¥–µ–ª–∏ Gemma-3n-E2B-it
"""

import sys
import time
from pathlib import Path
from typing import List, Dict, Any

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—é
sys.path.append(str(Path(__file__).parent))

from model_loader import GemmaEntropyAnalyzer

class EntropyExperimentRunner:
    """–ö–ª–∞—Å—Å –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ —Å —ç–Ω—Ç—Ä–æ–ø–∏–µ–π"""
    
    def __init__(self):
        self.analyzer = None
        
    def print_header(self):
        """–ö—Ä–∞—Å–∏–≤—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞"""
        print("\n" + "="*80)
        print("üß† –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢: –ê–Ω–∞–ª–∏–∑ —ç–Ω—Ç—Ä–æ–ø–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤ –º–æ–¥–µ–ª–∏ Gemma-3n-E2B-it")
        print("="*80)
        print("üìä –¶–µ–ª—å: –ò–∑–º–µ—Ä–∏—Ç—å –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤")
        print("üìê –§–æ—Ä–º—É–ª–∞: H_i = -‚àëP_i(j) * log‚ÇÇ(P_i(j))")
        print("="*80 + "\n")
        
    def print_section(self, title: str, emoji: str = "üìã"):
        """–ü–µ—á–∞—Ç—å –∑–∞–≥–æ–ª–æ–≤–∫–∞ —Å–µ–∫—Ü–∏–∏"""
        print(f"\n{emoji} {title}")
        print("-" * (len(title) + 4))
        
    def print_model_info(self, info: Dict[str, Any]):
        """–ö—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏"""
        self.print_section("–ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –ú–û–î–ï–õ–ò", "ü§ñ")
        
        print(f"üìõ –ú–æ–¥–µ–ª—å: {info['model_name']}")
        print(f"üìö –†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è: {info['vocab_size']:,} —Ç–æ–∫–µ–Ω–æ–≤")
        print(f"üíª –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {info['device']}")
        print(f"üî¢ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {info['parameters']:,}")
        print(f"üéØ –¢–∏–ø: {info['model_type']}")
        
    def print_generation_analysis(self, prompt: str, results: Dict[str, Any]):
        """–ö—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —ç–Ω—Ç—Ä–æ–ø–∏–∏"""
        
        self.print_section(f"–ì–ï–ù–ï–†–ê–¶–ò–Ø –° –ê–ù–ê–õ–ò–ó–û–ú –≠–ù–¢–†–û–ü–ò–ò", "üé≤")
        print(f"üéØ –ü—Ä–æ–º–ø—Ç: '{prompt}'")
        print(f"‚ú® –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: '{results['full_generated_text']}'")
        print(f"üìù –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç: '{results['complete_text']}'")
        
        generated_parts = results['generated_text_parts']
        entropies = results['entropies']
        probabilities = results['probabilities']
        
        print(f"\n–ü—Ä–æ—Ü–µ—Å—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ ({len(generated_parts)} —Ç–æ–∫–µ–Ω–æ–≤):")
        print("=" * 70)
        
        cumulative_text = prompt
        for i, (token_part, entropy, prob) in enumerate(zip(generated_parts, entropies, probabilities)):
            # –û—á–∏—â–∞–µ–º —Ç–æ–∫–µ–Ω –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            clean_token = token_part.replace('‚ñÅ', ' ')
                
            # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —ç–Ω—Ç—Ä–æ–ø–∏–∏
            if entropy < 0.1:
                interpretation = "–û—á–µ–Ω—å —É–≤–µ—Ä–µ–Ω"
            elif entropy < 0.5:
                interpretation = "–£–≤–µ—Ä–µ–Ω"  
            elif entropy < 1.0:
                interpretation = "–°—Ä–µ–¥–Ω—è—è –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å"
            elif entropy < 2.0:
                interpretation = "–ù–µ—É–≤–µ—Ä–µ–Ω"
            else:
                interpretation = "–û—á–µ–Ω—å –Ω–µ—É–≤–µ—Ä–µ–Ω"
            
            print(f"–®–∞–≥ {i+1:2d}: –¢–æ–∫–µ–Ω '{clean_token}'")
            print(f"         –≠–Ω—Ç—Ä–æ–ø–∏—è: {entropy:6.3f} –±–∏—Ç")
            print(f"         –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {prob:6.3f}")
            print(f"         –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {interpretation}")
            print("-" * 50)
            cumulative_text += token_part
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        if entropies:
            mean_entropy = sum(entropies) / len(entropies)
            min_entropy = min(entropies)
            max_entropy = max(entropies)
            
            self.print_section("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –ì–ï–ù–ï–†–ê–¶–ò–ò", "üìà")
            print(f"üìä –°—Ä–µ–¥–Ω—è—è —ç–Ω—Ç—Ä–æ–ø–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {mean_entropy:.3f} –±–∏—Ç")
            print(f"üìâ –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —ç–Ω—Ç—Ä–æ–ø–∏—è:       {min_entropy:.3f} –±–∏—Ç")
            print(f"üìà –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —ç–Ω—Ç—Ä–æ–ø–∏—è:      {max_entropy:.3f} –±–∏—Ç")
            print(f"üé≤ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤:           {len(entropies)}")
            
            # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ—Ü–µ—Å—Å–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            if mean_entropy < 0.5:
                generation_analysis = "–ú–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª–∞ –æ—á–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ"
                emoji = "üéØ"
            elif mean_entropy < 1.0:
                generation_analysis = "–£–≤–µ—Ä–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è"
                emoji = "‚úÖ"
            elif mean_entropy < 1.5:
                generation_analysis = "–£–º–µ—Ä–µ–Ω–Ω–∞—è –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"
                emoji = "ü§î"
            else:
                generation_analysis = "–í—ã—Å–æ–∫–∞—è –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"
                emoji = "‚ùì"
                
            print(f"\n{emoji} –ê–Ω–∞–ª–∏–∑ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {generation_analysis}")
            
            # –ù–∞–π–¥–µ–º —Å–∞–º—ã–π —É–≤–µ—Ä–µ–Ω–Ω—ã–π –∏ –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω—ã–π —à–∞–≥–∏
            min_idx = entropies.index(min_entropy)
            max_idx = entropies.index(max_entropy)
            
            print(f"üéØ –°–∞–º—ã–π —É–≤–µ—Ä–µ–Ω–Ω—ã–π —à–∞–≥: '{generated_parts[min_idx]}' (—ç–Ω—Ç—Ä–æ–ø–∏—è: {min_entropy:.3f})")
            print(f"‚ùì –°–∞–º—ã–π –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω—ã–π —à–∞–≥: '{generated_parts[max_idx]}' (—ç–Ω—Ç—Ä–æ–ø–∏—è: {max_entropy:.3f})")

    def print_entropy_analysis(self, text: str, results: Dict[str, Any]):
        """–ö—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ –∞–Ω–∞–ª–∏–∑–∞ —ç–Ω—Ç—Ä–æ–ø–∏–∏ (–¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ç–µ–∫—Å—Ç–∞)"""
        tokens = results['tokens']
        entropies = results['entropy'][0]  # –£–±–∏—Ä–∞–µ–º batch dimension
        
        self.print_section(f"–ê–ù–ê–õ–ò–ó –í–•–û–î–ù–û–ì–û –¢–ï–ö–°–¢–ê: '{text}'", "üîç")
        
        print("–ê–Ω–∞–ª–∏–∑ —Ç–æ–∫–µ–Ω–æ–≤:")
        print("=" * 50)
            
        for i, (token, entropy) in enumerate(zip(tokens, entropies)):
            # –û—á–∏—â–∞–µ–º —Ç–æ–∫–µ–Ω –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            clean_token = token.replace('‚ñÅ', ' ').replace('<bos>', '[–ù–ê–ß–ê–õ–û]')
            
            # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —É—Ä–æ–≤–Ω—è —ç–Ω—Ç—Ä–æ–ø–∏–∏
            entropy_val = float(entropy)
            if entropy_val < 0.1:
                interpretation = "–û—á–µ–Ω—å —É–≤–µ—Ä–µ–Ω"
            elif entropy_val < 0.5:
                interpretation = "–£–≤–µ—Ä–µ–Ω"
            elif entropy_val < 1.0:
                interpretation = "–°—Ä–µ–¥–Ω—è—è –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å"
            elif entropy_val < 2.0:
                interpretation = "–ù–µ—É–≤–µ—Ä–µ–Ω"
            else:
                interpretation = "–û—á–µ–Ω—å –Ω–µ—É–≤–µ—Ä–µ–Ω"
                
            print(f"–¢–æ–∫–µ–Ω {i+1:2d}: '{clean_token}'")
            print(f"          –≠–Ω—Ç—Ä–æ–ø–∏—è: {entropy_val:6.3f} –±–∏—Ç")
            print(f"          –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {interpretation}")
            print("-" * 40)
        
    def run_experiment(self, test_texts: List[str]):
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞"""
        self.print_header()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        self.print_section("–ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø", "üöÄ")
        print("‚è≥ –ó–∞–≥—Ä—É–∂–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —ç–Ω—Ç—Ä–æ–ø–∏–∏...")
        
        try:
            self.analyzer = GemmaEntropyAnalyzer()
            print("‚úÖ –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å–æ–∑–¥–∞–Ω")
            
            print("‚è≥ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å Gemma-3n-E2B-it...")
            print("   (–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç –ø—Ä–∏ –ø–µ—Ä–≤–æ–π –∑–∞–≥—Ä—É–∑–∫–µ)")
            
            start_time = time.time()
            self.analyzer.load_model()
            load_time = time.time() - start_time
            
            print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∑–∞ {load_time:.1f} —Å–µ–∫—É–Ω–¥")
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
            model_info = self.analyzer.get_model_info()
            self.print_model_info(model_info)
            
            # –ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —ç–Ω—Ç—Ä–æ–ø–∏–∏
            self.print_section("–ì–ï–ù–ï–†–ê–¢–ò–í–ù–´–ô –ê–ù–ê–õ–ò–ó –≠–ù–¢–†–û–ü–ò–ò", "üé≤")
            
            generation_prompts = [
                "–¢–µ–æ—Ä–µ–º–∞ –ü–∏—Ñ–∞–≥–æ—Ä–∞ –≥–ª–∞—Å–∏—Ç, —á—Ç–æ",
                "2 + 2 =",
                "–í –¥–∞–ª–µ–∫–æ–π –≥–∞–ª–∞–∫—Ç–∏–∫–µ",
                "–°—Ç–æ–ª–∏—Ü–∞ –†–æ—Å—Å–∏–∏"
            ]
            
            for i, prompt in enumerate(generation_prompts, 1):
                print(f"\nüéØ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è {i}/{len(generation_prompts)}")
                print("‚è≥ –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç —Å –∞–Ω–∞–ª–∏–∑–æ–º —ç–Ω—Ç—Ä–æ–ø–∏–∏...")
                
                start_time = time.time()
                results = self.analyzer.generate_with_entropy_analysis(prompt, max_new_tokens=8)
                generation_time = time.time() - start_time
                
                self.print_generation_analysis(prompt, results)
                print(f"‚è±Ô∏è  –í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {generation_time:.2f} —Å–µ–∫—É–Ω–¥")
                
                if i < len(generation_prompts):
                    print("\n" + "‚îÄ"*80)
                    
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            return False
            
        self.print_section("–≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢ –ó–ê–í–ï–†–®–ï–ù", "üéâ")
        print("‚úÖ –í—Å–µ —Ç–µ—Å—Ç—ã –≤—ã–ø–æ–ª–Ω–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
        print("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ —É—Ä–æ–≤–Ω–∏ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏")
        print("üî¨ –≠–Ω—Ç—Ä–æ–ø–∏—è –ø–æ–º–æ–≥–∞–µ—Ç –ø–æ–Ω—è—Ç—å, –Ω–∞—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª—å —É–≤–µ—Ä–µ–Ω–∞ –≤ —Å–≤–æ–∏—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö")
        print("\n" + "="*80 + "\n")
        
        return True

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞"""
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ —Ç–µ–∫—Å—Ç—ã —Ä–∞–∑–Ω–æ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
    test_texts = [
        "–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä!",
        "–¢–µ–æ—Ä–µ–º–∞ –ü–∏—Ñ–∞–≥–æ—Ä–∞ –≥–ª–∞—Å–∏—Ç, —á—Ç–æ",
        "–í –¥–∞–ª–µ–∫–æ–π –≥–∞–ª–∞–∫—Ç–∏–∫–µ",
        "2 + 2 =",
        "–ß—Ç–æ –≤—ã –¥—É–º–∞–µ—Ç–µ –æ"
    ]
    
    runner = EntropyExperimentRunner()
    success = runner.run_experiment(test_texts)
    
    if not success:
        print("üí• –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π")
        sys.exit(1)

if __name__ == "__main__":
    main()