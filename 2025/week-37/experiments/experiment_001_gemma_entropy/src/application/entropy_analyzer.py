"""
–ú–æ–¥—É–ª—å –ø—Ä–∏–∫–ª–∞–¥–Ω–æ–≥–æ —Å–ª–æ—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –∏ —ç–Ω—Ç—Ä–æ–ø–∏–∏.

–í—ã –¥–æ–ª–∂–Ω—ã —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –≤–µ—Å—å –∫–ª–∞—Å—Å GemmaEntropyAnalyzer.

–ü—Ä–µ–¥–ª–∞–≥–∞—é –≤–∞–º –¥—Ä–æ–ø–Ω—É—Ç—å –≤–µ—Å—å –∫–æ–¥, –∏ –æ—Å—Ç–∞–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ –ø–æ–¥—Å–∫–∞–∑–∫–∏ TODO, —á—Ç–æ –Ω—É–∂–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å ü§ó
"""

# –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞
import logging
from typing import Any, Dict, Optional

# –°—Ç–æ—Ä–æ–Ω–Ω–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
import torch

# –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –º–æ–¥—É–ª–∏ (DDD)
from domain.ports import ModelPort
from domain.entropy_calculator import EntropyCalculator

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class GemmaEntropyAnalyzer:
    """
    Description:
    ---------------
        –ö–ª–∞—Å—Å-–æ–±—ë—Ä—Ç–∫–∞ –ø—Ä–∏–∫–ª–∞–¥–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è: –ø–æ–ª—É—á–∞–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –æ—Ç –ø–æ—Ä—Ç–∞ –º–æ–¥–µ–ª–∏,
        —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —ç–Ω—Ç—Ä–æ–ø–∏—é —á–µ—Ä–µ–∑ –¥–æ–º–µ–Ω–Ω—ã–π —Å–µ—Ä–≤–∏—Å –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.

    Examples:
    ---------------
        >>> from infrastructure.gemma_model_manager import GemmaModelManager
        >>> manager = GemmaModelManager("config/experiment.yaml")
        >>> manager.load_model()
        >>> analyzer = GemmaEntropyAnalyzer(manager)
        >>> res = analyzer.analyze_text_entropy("–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä!")
        >>> "entropy" in res
        True
    """

    def __init__(self, model_port: ModelPort, calculator: Optional[EntropyCalculator] = None) -> None:
        """
        Description:
        ---------------
            –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä, —Å–æ—Ö—Ä–∞–Ω—è—è –ø–æ—Ä—Ç –º–æ–¥–µ–ª–∏ –∏ –¥–æ–º–µ–Ω–Ω—ã–π –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä.

        Args:
        ---------------
            model_port: —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è ModelPort (–∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞)
            calculator: –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä EntropyCalculator

        Returns:
        ---------------
            None
        """
        # TODO: —Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –≤ –∞—Ç—Ä–∏–±—É—Ç–∞—Ö —ç–∫–∑–µ–º–ø–ª—è—Ä–∞:
        # - self.model = model_port
        # - self.calculator = calculator or EntropyCalculator()

        # pass

        self.model = model_port
        self.calculator = calculator or EntropyCalculator()

    def get_token_probabilities(self, text: str) -> Dict[str, Any]:
        """
        Description:
        ---------------
            –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ—Ç –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç, –≤—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ –º–æ–¥–µ–ª–∏ –∏
            –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å —Ç–æ–∫–µ–Ω–∞–º–∏, –∏—Ö –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞–º–∏, –ª–æ–≥–∏—Ç–∞–º–∏ –∏
            –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏ –ø–æ —Å–ª–æ–≤–∞—Ä—é –Ω–∞ –∫–∞–∂–¥–æ–π –ø–æ–∑–∏—Ü–∏–∏.

        Args:
        ---------------
            text: –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π —Ç–æ–∫–µ–Ω–æ–≤

        Returns:
        ---------------
            dict: —Å–ª–æ–≤–∞—Ä—å —Å –∫–ª—é—á–∞–º–∏:
                - 'tokens': —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤
                - 'token_ids': —Ç–µ–Ω–∑–æ—Ä –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ —Ç–æ–∫–µ–Ω–æ–≤
                - 'probabilities': —Ç–µ–Ω–∑–æ—Ä –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π (B, T, V)
                - 'logits': —Ç–µ–Ω–∑–æ—Ä –ª–æ–≥–∏—Ç–æ–≤ (B, T, V)

        Raises:
        ---------------
            RuntimeError: –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞

        Examples:
        ---------------
            >>> from infrastructure.gemma_model_manager import GemmaModelManager
            >>> manager = GemmaModelManager("config/experiment.yaml")
            >>> manager.load_model()
            >>> analyzer = GemmaEntropyAnalyzer(manager)
            >>> res = analyzer.get_token_probabilities("–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä!")
            >>> set(res.keys()) == {"tokens", "token_ids", "probabilities", "logits"}
            True
        """
        # TODO: —Ä–µ–∞–ª–∏–∑—É–π—Ç–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π —á–µ—Ä–µ–∑ –ø–æ—Ä—Ç:
        # 1. –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–π—Ç–µ —Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ self.model.tokenize(..., max_length)
        # 2. –ü–æ–ª—É—á–∏—Ç–µ outputs = self.model.forward(**inputs)
        # 3. –ò–∑–≤–ª–µ–∫–∏—Ç–µ logits –∏–∑ outputs
        # 4. –ü—Ä–∏–º–µ–Ω–∏—Ç–µ torch.softmax –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        # 5. –î–µ–∫–æ–¥–∏—Ä—É–π—Ç–µ —Ç–æ–∫–µ–Ω—ã —á–µ—Ä–µ–∑ self.model.convert_ids_to_tokens
        # 6. –í–µ—Ä–Ω–∏—Ç–µ —Å–ª–æ–≤–∞—Ä—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞

        # pass

        inputs = self.model.tokenize(text, max_length=self.model.context_length())
        outputs = self.model.forward(**inputs)
        logits = outputs.logits
        probabilities = torch.softmax(logits, dim=-1)
        tokens = self.model.convert_ids_to_tokens(inputs["input_ids"][0])

        logger.info("Tokens: %s", tokens)
        logger.info("Token IDs: %s", inputs["input_ids"][0])
        logger.info("Probabilities: %s", probabilities)
        logger.info("Logits: %s", logits)

        return {
            "tokens": tokens,
            "token_ids": inputs["input_ids"][0],
            "probabilities": probabilities,
            "logits": logits,
        }

    def analyze_text_entropy(self, text: str) -> Dict[str, Any]:
        """
        Description:
        ---------------
            –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª –∞–Ω–∞–ª–∏–∑–∞: –ø–æ–ª—É—á–∞–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —Ç–æ–∫–µ–Ω–æ–≤,
            —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —ç–Ω—Ç—Ä–æ–ø–∏—é –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç.

        Args:
        ---------------
            text: —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.

        Returns:
        ---------------
            dict: —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º –∫–ª—é—á–æ–º 'entropy'.

        Examples:
        ---------------
            >>> from infrastructure.gemma_model_manager import GemmaModelManager
            >>> manager = GemmaModelManager()
            >>> manager.load_model()
            >>> analyzer = GemmaEntropyAnalyzer(manager)
            >>> res = analyzer.analyze_text_entropy("–ü—Ä–∏–º–µ—Ä —Ç–µ–∫—Å—Ç–∞")
            >>> "entropy" in res
            True
        """
        # TODO: —Ä–µ–∞–ª–∏–∑—É–π—Ç–µ —Å–ª–µ–¥—É—é—â—É—é –ª–æ–≥–∏–∫—É
        # 1. –í—ã–∑–≤–∞—Ç—å self.get_token_probabilities(text) –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        # 2. –ò–∑–≤–ª–µ—á—å probabilities –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        # 3. –í—ã–∑–≤–∞—Ç—å self.calculator.calculate_entropy(probabilities)
        # 4. –î–æ–±–∞–≤–∏—Ç—å –∫–ª—é—á 'entropy' –≤ —Å–ª–æ–≤–∞—Ä—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏ –≤–µ—Ä–Ω—É—Ç—å

        results = self.get_token_probabilities(text)
        entropy = self.calculator.calculate_entropy(results["probabilities"])
        results["entropy"] = entropy
        return results

    def generate_with_entropy_analysis(self, prompt: str, max_new_tokens: int = 10) -> Dict[str, Any]:
        """
        Description:
        ---------------
            –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ—à–∞–≥–æ–≤—ã–º –∞–Ω–∞–ª–∏–∑–æ–º —ç–Ω—Ç—Ä–æ–ø–∏–∏ –∫–∞–∂–¥–æ–≥–æ —Ç–æ–∫–µ–Ω–∞

        Args:
        ---------------
            prompt: –ù–∞—á–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            max_new_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤

        Returns:
        ---------------
            dict: –ü–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å —ç–Ω—Ç—Ä–æ–ø–∏–µ–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —à–∞–≥–∞
        """
        # TODO: —Ä–µ–∞–ª–∏–∑—É–π—Ç–µ —Å–ª–µ–¥—É—é—â—É—é –ª–æ–≥–∏–∫—É
        # 1. –¢–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–º–ø—Ç —á–µ—Ä–µ–∑ –ø–æ—Ä—Ç
        # 2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–ø–∏—Å–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        # 3. –í—ã–ø–æ–ª–Ω–∏—Ç—å –∞–Ω–∞–ª–∏–∑ —ç–Ω—Ç—Ä–æ–ø–∏–∏ –¥–ª—è –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
        # 4. –¶–∏–∫–ª –ø–æ —à–∞–≥–∞–º –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–∂–∞–¥–Ω—ã–π –≤—ã–±–æ—Ä argmax):
        #    - forward, –∏–∑–≤–ª–µ—á—å logits[-1]
        #    - softmax ‚Üí –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        #    - –≤—ã–±—Ä–∞—Ç—å next_token_id
        #    - –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–∫–µ–Ω –≤ —Ç–µ–∫—Å—Ç
        #    - —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å —ç–Ω—Ç—Ä–æ–ø–∏—é —á–µ—Ä–µ–∑ self.calculator
        #    - —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ —Ä–∞—Å—à–∏—Ä–∏—Ç—å input_ids
        #    - –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ EOS
        # 5. –°–æ–±—Ä–∞—Ç—å –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –∏ –≤–µ—Ä–Ω—É—Ç—å —Å–ª–æ–≤–∞—Ä—å

        inputs = self.model.tokenize(
            prompt,
            max_length=self.model.context_length(),
        )

        generated_tokens = []
        generated_text_parts = []
        entropies = []
        probabilities_list = []

        current_input_ids = inputs["input_ids"].clone()

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —ç–Ω—Ç—Ä–æ–ø–∏—é –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
        with torch.no_grad():
            outputs = self.model.forward(input_ids=current_input_ids)
            logits = outputs.logits
            probs = torch.softmax(logits, dim=-1)
            last_token_probs = probs[0, -1, :]
            _ = self.calculator.calculate_entropy(last_token_probs.unsqueeze(0).unsqueeze(0))

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–æ–∫–µ–Ω—ã –æ–¥–∏–Ω –∑–∞ –¥—Ä—É–≥–∏–º
        for _ in range(max_new_tokens):
            with torch.no_grad():
                outputs = self.model.forward(input_ids=current_input_ids)
                logits = outputs.logits
                next_token_logits = logits[0, -1, :]
                next_token_probs = torch.softmax(next_token_logits, dim=-1)
                next_token_id = torch.argmax(next_token_probs, dim=-1).unsqueeze(0).unsqueeze(0)

                next_token_text = self.model.decode_token(next_token_id)
                token_entropy = self.calculator.calculate_entropy(next_token_probs.unsqueeze(0).unsqueeze(0))

                generated_tokens.append(int(next_token_id[0, 0]))
                generated_text_parts.append(next_token_text)
                entropies.append(float(token_entropy[0, 0]))
                probabilities_list.append(float(next_token_probs[next_token_id[0, 0]]))

                current_input_ids = torch.cat([current_input_ids, next_token_id], dim=-1)

                if next_token_id[0, 0] == self.model.eos_token_id():
                    break

        full_generated = self.model.decode_sequence(generated_tokens) if generated_tokens else ""

        return {
            'prompt': prompt,
            'generated_tokens': generated_tokens,
            'generated_text_parts': generated_text_parts,
            'full_generated_text': full_generated,
            'complete_text': prompt + full_generated,
            'entropies': entropies,
            'probabilities': probabilities_list,
            'generation_steps': len(generated_tokens)
        }
